{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aab0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "img =cv2.imread('braille_page_2.jpg')\n",
    "\n",
    "# constants/changables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d67b092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nepali Braille 6-dot encoding map\n",
    "# Dot numbering:\n",
    "# 1 4\n",
    "# 2 5\n",
    "# 3 6\n",
    "\n",
    "def dots_to_bit(dots):\n",
    "    \"\"\"Convert list of active dots (1-6) to a 6-bit integer.\"\"\"\n",
    "    val = 0\n",
    "    for d in dots:\n",
    "        val |= 1 << (6 - d)\n",
    "    return val\n",
    "\n",
    "braille_map = {\n",
    "    dots_to_bit([1]): 'अ',\n",
    "    dots_to_bit([3, 4, 5]): 'आ',\n",
    "    dots_to_bit([2, 4]): 'इ',\n",
    "    dots_to_bit([3, 5]): 'ई',\n",
    "    dots_to_bit([1, 3, 6]): 'उ',\n",
    "    dots_to_bit([1, 2, 5, 6]): 'ऊ',\n",
    "    dots_to_bit([1, 5, 6]): 'ऋ',\n",
    "    dots_to_bit([1, 5]): 'ए',\n",
    "    dots_to_bit([3, 4]): 'ऐ',\n",
    "    dots_to_bit([1, 3, 5]): 'ओ',\n",
    "    dots_to_bit([2, 4, 6]): 'औ',\n",
    "    dots_to_bit([1, 6]): 'अं',\n",
    "    dots_to_bit([6]): 'अः',\n",
    "\n",
    "    dots_to_bit([1, 3]): 'क',\n",
    "    dots_to_bit([4, 6]): 'ख',\n",
    "    dots_to_bit([1, 2, 4, 5]): 'ग',\n",
    "    dots_to_bit([1, 2, 6]): 'घ',\n",
    "    dots_to_bit([3, 4, 6]): 'ङ',\n",
    "    dots_to_bit([1, 4]): 'च',\n",
    "    dots_to_bit([1, 6]): 'छ',\n",
    "    dots_to_bit([2, 4, 5]): 'ज',\n",
    "    dots_to_bit([3, 5, 6]): 'झ',\n",
    "    dots_to_bit([2, 5]): 'ञ',\n",
    "    dots_to_bit([2, 3, 4, 6]): 'ट',\n",
    "    dots_to_bit([2, 4, 5, 6]): 'ठ',\n",
    "    dots_to_bit([1, 2, 4, 6]): 'ड',\n",
    "    dots_to_bit([1, 2, 3, 4, 6]): 'ढ',\n",
    "    dots_to_bit([3, 4, 5, 6]): 'ण',\n",
    "    dots_to_bit([2, 3, 4, 5]): 'त',\n",
    "    dots_to_bit([1, 4, 5, 6]): 'थ',\n",
    "    dots_to_bit([1, 4, 5]): 'द',\n",
    "    dots_to_bit([2, 3, 5, 6]): 'ध',\n",
    "    dots_to_bit([1, 3, 4, 5]): 'न',\n",
    "    dots_to_bit([1, 2, 3, 4]): 'प',\n",
    "    dots_to_bit([2, 3, 5]): 'फ',\n",
    "    dots_to_bit([1, 2]): 'ब',\n",
    "    dots_to_bit([4, 5]): 'भ',\n",
    "    dots_to_bit([1, 3, 4]): 'म',\n",
    "    dots_to_bit([1, 3, 4, 5, 6]): 'य',\n",
    "    dots_to_bit([1, 2, 3, 5]): 'र',\n",
    "    dots_to_bit([1, 2, 3]): 'ल',\n",
    "    dots_to_bit([1, 2, 3, 6]): 'व',\n",
    "    dots_to_bit([1, 4, 6]): 'श',\n",
    "    dots_to_bit([1, 2, 3, 4, 6]): 'ष',\n",
    "    dots_to_bit([2, 3, 4]): 'स',\n",
    "    dots_to_bit([1, 2, 5]): 'ह',\n",
    "    dots_to_bit([1, 2, 3, 4, 5]): 'क्ष',\n",
    "    dots_to_bit([1, 5, 6]): 'ज्ञ',\n",
    "}\n",
    "\n",
    "# Special compound (multi-cell)\n",
    "braille_map_compound = {\n",
    "    # 'त्र' uses two cells: [5] + [1,2,4,5,6]\n",
    "    (dots_to_bit([5]), dots_to_bit([1, 2, 4, 5, 6])): 'त्र',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480109cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing Block\n",
    "def preprocess_braille_image(\n",
    "    img_gray,\n",
    "    method=\"adaptive\",   # \"adaptive\", \"sauvola\", or \"otsu\"\n",
    "    block_size=31,       # for adaptive/local threshold (odd, e.g. 25–51)\n",
    "    C=10,                # constant for adaptive/local threshold\n",
    "    morph_open=3,        # kernel size for opening (3–7)\n",
    "    morph_close=5,       # kernel size for closing (3–7)\n",
    "    apply_tophat=False,  # True if embossing subtle\n",
    "    min_blob_area=5      # small debris threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess Braille grayscale image for dot detection.\n",
    "    Returns binary image (dots = white, background = black).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Step 1: Denoise slightly (optional but helps) ---\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "\n",
    "    # --- Step 2: Binarization ---\n",
    "    if method == \"adaptive\":\n",
    "        bin_img = cv2.adaptiveThreshold(\n",
    "            img_blur, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,  # invert → dots white on black\n",
    "            block_size, C\n",
    "        )\n",
    "    elif method == \"otsu\":\n",
    "        _, bin_img = cv2.threshold(\n",
    "            img_blur, 0, 255,\n",
    "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )\n",
    "    elif method == \"sauvola\":\n",
    "        # Sauvola via scikit-image if available\n",
    "        from skimage.filters import threshold_sauvola\n",
    "        thresh_s = threshold_sauvola(img_blur, window_size=block_size, k=0.2)\n",
    "        bin_img = (img_blur < thresh_s).astype(np.uint8) * 255\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of: adaptive, otsu, sauvola\")\n",
    "\n",
    "    # --- Step 3: Morphological cleanup ---\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_open, morph_open))\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_close, morph_close))\n",
    "\n",
    "    # Opening: remove small noise\n",
    "    cleaned = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    # Closing: fill small holes in dots\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # --- Step 4: Optional top-hat (enhance embossing if faint) ---\n",
    "    if apply_tophat:\n",
    "        kernel_th = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        tophat = cv2.morphologyEx(img_gray, cv2.MORPH_TOPHAT, kernel_th)\n",
    "        cleaned = cv2.bitwise_or(cleaned, (tophat > 0).astype(np.uint8) * 255)\n",
    "\n",
    "    # --- Step 5: Optional small blob removal ---\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned, connectivity=8)\n",
    "    mask = np.zeros_like(cleaned)\n",
    "    for i in range(1, num_labels):  # skip background\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_blob_area:\n",
    "            mask[labels == i] = 255\n",
    "\n",
    "    return mask\n",
    "\n",
    "def consolidate_braille_dots(binary_img):\n",
    "    \"\"\"\n",
    "    Fix broken or irregular Braille dots before centroid detection.\n",
    "    Returns cleaned binary image.\n",
    "    \"\"\"\n",
    "    # Step 1. Close small holes inside each dot\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closed = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # Step 2. Remove small specks between dots\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    # Step 3. Optional: smooth edges slightly\n",
    "    blurred = cv2.GaussianBlur(opened, (3, 3), 0)\n",
    "    _, smooth_bin = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return smooth_bin\n",
    "\n",
    "def detect_braille_dots(\n",
    "    binary_img,\n",
    "    method=\"connected\",      # \"connected\", \"blob\", or \"log\"\n",
    "    min_area=5,              # adjust based on resolution (~π*r_min²)\n",
    "    max_area=200,            # reject large merged blobs\n",
    "    circularity_thresh=0.6,  # for blob detector\n",
    "    inertia_thresh=0.5,      # for blob detector\n",
    "    log_min_sigma=1,         # for LoG\n",
    "    log_max_sigma=4,\n",
    "    log_num_sigma=10,\n",
    "    log_threshold=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect Braille dot centroids in a preprocessed binary image.\n",
    "    Returns list of (x, y) coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    centroids = []\n",
    "\n",
    "    # --- Option 1: Connected Components ---\n",
    "    if method == \"connected\":\n",
    "        num_labels, labels, stats, ctds = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "        for i in range(1, num_labels):  # skip background\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            if min_area <= area <= max_area:\n",
    "                x, y = ctds[i]\n",
    "                centroids.append((float(x), float(y)))\n",
    "\n",
    "    # --- Option 2: OpenCV SimpleBlobDetector ---\n",
    "    elif method == \"blob\":\n",
    "        params = cv2.SimpleBlobDetector_Params()\n",
    "        params.filterByArea = True\n",
    "        params.minArea = min_area\n",
    "        params.maxArea = max_area\n",
    "        params.filterByCircularity = True\n",
    "        params.minCircularity = circularity_thresh\n",
    "        params.filterByInertia = True\n",
    "        params.minInertiaRatio = inertia_thresh\n",
    "        params.filterByConvexity = False\n",
    "\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "        keypoints = detector.detect(binary_img)\n",
    "        centroids = [(kp.pt[0], kp.pt[1]) for kp in keypoints]\n",
    "\n",
    "    # --- Option 3: Laplacian of Gaussian (LoG) ---\n",
    "    elif method == \"log\":\n",
    "        from skimage.feature import blob_log\n",
    "        binary_float = binary_img.astype(np.float32) / 255.0\n",
    "        blobs = blob_log(binary_float,\n",
    "                         min_sigma=log_min_sigma,\n",
    "                         max_sigma=log_max_sigma,\n",
    "                         num_sigma=log_num_sigma,\n",
    "                         threshold=log_threshold)\n",
    "        # Each blob: (y, x, sigma)\n",
    "        centroids = [(float(x), float(y)) for y, x, s in blobs]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of: 'connected', 'blob', or 'log'\")\n",
    "\n",
    "    return np.array(centroids, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb51c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dots: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "preprocessed = preprocess_braille_image(img_gray, method=\"sauvola\")\n",
    "# cv2.imshow('Before', img_gray)\n",
    "# cv2.imshow('Preprocessed', binary)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"braille_page_output_1.jpg\",img)\n",
    "binary = consolidate_braille_dots(preprocessed)\n",
    "dots = detect_braille_dots(binary, method=\"connected\", min_area=15, max_area=220)\n",
    "print(\"Detected dots:\", len(dots))\n",
    "# print(dots)\n",
    "for (x, y) in dots:\n",
    "    cv2.circle(img, (int(x), int(y)), 7, (0,0,255), -1)\n",
    "# Store results\n",
    "height, width, channels = img.shape\n",
    "# Create a white image with the same size\n",
    "output_image = np.ones((height, width, channels), dtype=np.uint8) * 255\n",
    "for (x, y) in dots:\n",
    "    cv2.circle(output_image, (int(x), int(y)), 4, (0,0,0), -1)\n",
    "cv2.imwrite(\"braille_page_output_2.jpg\",binary)\n",
    "cv2.imwrite(\"braille_page_output_3.jpg\",img)\n",
    "cv2.imwrite(\"braille_page_output_4.jpg\",output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c17da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 192x640 (no detections), 113.2ms\n",
      "Speed: 11.5ms preprocess, 113.2ms inference, 8.9ms postprocess per image at shape (1, 3, 192, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"braille_yolov11_nano.pt\")\n",
    "# model = YOLO(\"best_2.pt\")\n",
    "# model = YOLO(\"best_1.pt\")\n",
    "# model = YOLO(\"best.pt\")\n",
    "# model = YOLO(\"yolov8n.pt\")\n",
    "# model = YOLO(\"Braille_Yolov11_old.pt\")\n",
    "# img = cv2.imread(\"braille_page_2.jpg\")\n",
    "results = model(output_image)\n",
    "annotated = results[0].plot()\n",
    "\n",
    "cv2.imshow(\"Detections\", annotated)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
