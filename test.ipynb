{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "img =cv2.imread('braille_page_3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nepali Braille 6-dot encoding map\n",
    "# Dot numbering:\n",
    "# 1 4\n",
    "# 2 5\n",
    "# 3 6\n",
    "\n",
    "def dots_to_bit(dots):\n",
    "    \"\"\"Convert list of active dots (1â€“6) to a 6-bit integer.\"\"\"\n",
    "    val = 0\n",
    "    for d in dots:\n",
    "        val |= 1 << (6 - d)\n",
    "    return val\n",
    "\n",
    "braille_map = {\n",
    "    dots_to_bit([1]): 'à¤…',\n",
    "    dots_to_bit([3, 4, 5]): 'à¤†',\n",
    "    dots_to_bit([2, 4]): 'à¤‡',\n",
    "    dots_to_bit([3, 5]): 'à¤ˆ',\n",
    "    dots_to_bit([1, 3, 6]): 'à¤‰',\n",
    "    dots_to_bit([1, 2, 5, 6]): 'à¤Š',\n",
    "    dots_to_bit([1, 5, 6]): 'à¤‹',\n",
    "    dots_to_bit([1, 5]): 'à¤',\n",
    "    dots_to_bit([3, 4]): 'à¤',\n",
    "    dots_to_bit([1, 3, 5]): 'à¤“',\n",
    "    dots_to_bit([2, 4, 6]): 'à¤”',\n",
    "    dots_to_bit([1, 6]): 'à¤…à¤‚',\n",
    "    dots_to_bit([6]): 'à¤…à¤ƒ',\n",
    "\n",
    "    dots_to_bit([1, 3]): 'à¤•',\n",
    "    dots_to_bit([4, 6]): 'à¤–',\n",
    "    dots_to_bit([1, 2, 4, 5]): 'à¤—',\n",
    "    dots_to_bit([1, 2, 6]): 'à¤˜',\n",
    "    dots_to_bit([3, 4, 6]): 'à¤™',\n",
    "    dots_to_bit([1, 4]): 'à¤š',\n",
    "    dots_to_bit([1, 6]): 'à¤›',\n",
    "    dots_to_bit([2, 4, 5]): 'à¤œ',\n",
    "    dots_to_bit([3, 5, 6]): 'à¤',\n",
    "    dots_to_bit([2, 5]): 'à¤ž',\n",
    "    dots_to_bit([2, 3, 4, 6]): 'à¤Ÿ',\n",
    "    dots_to_bit([2, 4, 5, 6]): 'à¤ ',\n",
    "    dots_to_bit([1, 2, 4, 6]): 'à¤¡',\n",
    "    dots_to_bit([1, 2, 3, 4, 6]): 'à¤¢',\n",
    "    dots_to_bit([3, 4, 5, 6]): 'à¤£',\n",
    "    dots_to_bit([2, 3, 4, 5]): 'à¤¤',\n",
    "    dots_to_bit([1, 4, 5, 6]): 'à¤¥',\n",
    "    dots_to_bit([1, 4, 5]): 'à¤¦',\n",
    "    dots_to_bit([2, 3, 5, 6]): 'à¤§',\n",
    "    dots_to_bit([1, 3, 4, 5]): 'à¤¨',\n",
    "    dots_to_bit([1, 2, 3, 4]): 'à¤ª',\n",
    "    dots_to_bit([2, 3, 5]): 'à¤«',\n",
    "    dots_to_bit([1, 2]): 'à¤¬',\n",
    "    dots_to_bit([4, 5]): 'à¤­',\n",
    "    dots_to_bit([1, 3, 4]): 'à¤®',\n",
    "    dots_to_bit([1, 3, 4, 5, 6]): 'à¤¯',\n",
    "    dots_to_bit([1, 2, 3, 5]): 'à¤°',\n",
    "    dots_to_bit([1, 2, 3]): 'à¤²',\n",
    "    dots_to_bit([1, 2, 3, 6]): 'à¤µ',\n",
    "    dots_to_bit([1, 4, 6]): 'à¤¶',\n",
    "    dots_to_bit([1, 2, 3, 4, 6]): 'à¤·',\n",
    "    dots_to_bit([2, 3, 4]): 'à¤¸',\n",
    "    dots_to_bit([1, 2, 5]): 'à¤¹',\n",
    "    dots_to_bit([1, 2, 3, 4, 5]): 'à¤•à¥à¤·',\n",
    "    dots_to_bit([1, 5, 6]): 'à¤œà¥à¤ž',\n",
    "}\n",
    "\n",
    "# Special compound (multi-cell)\n",
    "braille_map_compound = {\n",
    "    # 'à¤¤à¥à¤°' uses two cells: [5] + [1,2,4,5,6]\n",
    "    (dots_to_bit([5]), dots_to_bit([1, 2, 4, 5, 6])): 'à¤¤à¥à¤°',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480109cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing Block\n",
    "def preprocess_braille_image(\n",
    "    img_gray,\n",
    "    method=\"adaptive\",   # \"adaptive\", \"sauvola\", or \"otsu\"\n",
    "    block_size=31,       # for adaptive/local threshold (odd, e.g. 25â€“51)\n",
    "    C=10,                # constant for adaptive/local threshold\n",
    "    morph_open=3,        # kernel size for opening (3â€“7)\n",
    "    morph_close=5,       # kernel size for closing (3â€“7)\n",
    "    apply_tophat=False,  # True if embossing subtle\n",
    "    min_blob_area=5      # small debris threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess Braille grayscale image for dot detection.\n",
    "    Returns binary image (dots = white, background = black).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Step 1: Denoise slightly (optional but helps) ---\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "\n",
    "    # --- Step 2: Binarization ---\n",
    "    if method == \"adaptive\":\n",
    "        bin_img = cv2.adaptiveThreshold(\n",
    "            img_blur, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,  # invert â†’ dots white on black\n",
    "            block_size, C\n",
    "        )\n",
    "    elif method == \"otsu\":\n",
    "        _, bin_img = cv2.threshold(\n",
    "            img_blur, 0, 255,\n",
    "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )\n",
    "    elif method == \"sauvola\":\n",
    "        # Sauvola via scikit-image if available\n",
    "        from skimage.filters import threshold_sauvola\n",
    "        thresh_s = threshold_sauvola(img_blur, window_size=block_size, k=0.2)\n",
    "        bin_img = (img_blur < thresh_s).astype(np.uint8) * 255\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of: adaptive, otsu, sauvola\")\n",
    "\n",
    "    # --- Step 3: Morphological cleanup ---\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_open, morph_open))\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_close, morph_close))\n",
    "\n",
    "    # Opening: remove small noise\n",
    "    cleaned = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    # Closing: fill small holes in dots\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # --- Step 4: Optional top-hat (enhance embossing if faint) ---\n",
    "    if apply_tophat:\n",
    "        kernel_th = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        tophat = cv2.morphologyEx(img_gray, cv2.MORPH_TOPHAT, kernel_th)\n",
    "        cleaned = cv2.bitwise_or(cleaned, (tophat > 0).astype(np.uint8) * 255)\n",
    "\n",
    "    # --- Step 5: Optional small blob removal ---\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned, connectivity=8)\n",
    "    mask = np.zeros_like(cleaned)\n",
    "    for i in range(1, num_labels):  # skip background\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_blob_area:\n",
    "            mask[labels == i] = 255\n",
    "\n",
    "    return mask\n",
    "\n",
    "def consolidate_braille_dots(binary_img):\n",
    "    \"\"\"\n",
    "    Fix broken or irregular Braille dots before centroid detection.\n",
    "    Returns cleaned binary image.\n",
    "    \"\"\"\n",
    "    # Step 1. Close small holes inside each dot\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closed = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # Step 2. Remove small specks between dots\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    # Step 3. Optional: smooth edges slightly\n",
    "    blurred = cv2.GaussianBlur(opened, (3, 3), 0)\n",
    "    _, smooth_bin = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return smooth_bin\n",
    "\n",
    "def detect_braille_dots(\n",
    "    binary_img,\n",
    "    method=\"connected\",      # \"connected\", \"blob\", or \"log\"\n",
    "    min_area=5,              # adjust based on resolution (~Ï€*r_minÂ²)\n",
    "    max_area=200,            # reject large merged blobs\n",
    "    circularity_thresh=0.6,  # for blob detector\n",
    "    inertia_thresh=0.5,      # for blob detector\n",
    "    log_min_sigma=1,         # for LoG\n",
    "    log_max_sigma=4,\n",
    "    log_num_sigma=10,\n",
    "    log_threshold=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect Braille dot centroids in a preprocessed binary image.\n",
    "    Returns list of (x, y) coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    centroids = []\n",
    "\n",
    "    # --- Option 1: Connected Components ---\n",
    "    if method == \"connected\":\n",
    "        num_labels, labels, stats, ctds = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "        for i in range(1, num_labels):  # skip background\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            if min_area <= area <= max_area:\n",
    "                x, y = ctds[i]\n",
    "                centroids.append((float(x), float(y)))\n",
    "\n",
    "    # --- Option 2: OpenCV SimpleBlobDetector ---\n",
    "    elif method == \"blob\":\n",
    "        params = cv2.SimpleBlobDetector_Params()\n",
    "        params.filterByArea = True\n",
    "        params.minArea = min_area\n",
    "        params.maxArea = max_area\n",
    "        params.filterByCircularity = True\n",
    "        params.minCircularity = circularity_thresh\n",
    "        params.filterByInertia = True\n",
    "        params.minInertiaRatio = inertia_thresh\n",
    "        params.filterByConvexity = False\n",
    "\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "        keypoints = detector.detect(binary_img)\n",
    "        centroids = [(kp.pt[0], kp.pt[1]) for kp in keypoints]\n",
    "\n",
    "    # --- Option 3: Laplacian of Gaussian (LoG) ---\n",
    "    elif method == \"log\":\n",
    "        from skimage.feature import blob_log\n",
    "        binary_float = binary_img.astype(np.float32) / 255.0\n",
    "        blobs = blob_log(binary_float,\n",
    "                         min_sigma=log_min_sigma,\n",
    "                         max_sigma=log_max_sigma,\n",
    "                         num_sigma=log_num_sigma,\n",
    "                         threshold=log_threshold)\n",
    "        # Each blob: (y, x, sigma)\n",
    "        centroids = [(float(x), float(y)) for y, x, s in blobs]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of: 'connected', 'blob', or 'log'\")\n",
    "\n",
    "    return np.array(centroids, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb51c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "preprocessed = preprocess_braille_image(img_gray, method=\"sauvola\")\n",
    "# cv2.imshow('Before', img_gray)\n",
    "# cv2.imshow('Preprocessed', binary)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"braille_page_output_1.jpg\",img)\n",
    "binary = consolidate_braille_dots(preprocessed)\n",
    "dots = detect_braille_dots(binary, method=\"connected\", min_area=15, max_area=220)\n",
    "print(\"Detected dots:\", len(dots))\n",
    "# print(dots)\n",
    "for (x, y) in dots:\n",
    "    cv2.circle(img, (int(x), int(y)), 7, (0,0,255), -1)\n",
    "# Store results\n",
    "height, width, channels = img.shape\n",
    "# Create a white image with the same size\n",
    "output_image = np.ones((height, width, channels), dtype=np.uint8) * 255\n",
    "for (x, y) in dots:\n",
    "    cv2.circle(output_image, (int(x), int(y)), 4, (0,0,0), -1)\n",
    "cv2.imwrite(\"braille_page_output_2.jpg\",binary)\n",
    "cv2.imwrite(\"braille_page_output_3.jpg\",img)\n",
    "cv2.imwrite(\"braille_page_output_4.jpg\",output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load the trained YOLOv11 model\n",
    "model_path = \"braille_best.pt\"  # your trained weights\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Read image with OpenCV\n",
    "# image_path = \"test_braille.jpg\"\n",
    "# image = cv2.imread(image_path)\n",
    "image = output_image\n",
    "\n",
    "# Run detection\n",
    "results = model.predict(source=image, imgsz=640, conf=0.3, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Visualize detections\n",
    "annotated_frame = results[0].plot()\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow(\"Braille Detection\", annotated_frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Optionally save the annotated output\n",
    "# cv2.imwrite(\"braille_detected.jpg\", annotated_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbfc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_distances(dot_coordinates):\n",
    "#     \"\"\"\n",
    "#     Calculate the average vertical (D_V), horizontal (D_H), and inter-cell horizontal (C_H) distances\n",
    "#     based on the given dot coordinates.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - dot_coordinates: List of (x, y) coordinates of the dots.\n",
    "    \n",
    "#     Returns:\n",
    "#     - D_V: Average vertical distance.\n",
    "#     - D_H: Average horizontal distance.\n",
    "#     - C_H: Average inter-cell horizontal distance.\n",
    "#     \"\"\"\n",
    "#     # Convert coordinates to numpy array for easier manipulation\n",
    "#     dots = np.array(dot_coordinates)\n",
    "    \n",
    "#     # Calculate all pairwise vertical distances\n",
    "#     vertical_distances = []\n",
    "#     for i in range(len(dots)):\n",
    "#         for j in range(i + 1, len(dots)):\n",
    "#             if abs(dots[i][0] - dots[j][0]) < 10:  # Close enough in the horizontal direction\n",
    "#                 vertical_distances.append(abs(dots[i][1] - dots[j][1]))\n",
    "    \n",
    "#     D_V = np.mean(vertical_distances) if vertical_distances else 0\n",
    "    \n",
    "#     # Calculate all pairwise horizontal distances\n",
    "#     horizontal_distances = []\n",
    "#     for i in range(len(dots)):\n",
    "#         for j in range(i + 1, len(dots)):\n",
    "#             if abs(dots[i][1] - dots[j][1]) < 10:  # Close enough in the vertical direction\n",
    "#                 horizontal_distances.append(abs(dots[i][0] - dots[j][0]))\n",
    "    \n",
    "#     D_H = np.mean(horizontal_distances) if horizontal_distances else 0\n",
    "    \n",
    "#     # Sort the dots by their x-coordinate to estimate inter-cell distances\n",
    "#     dots_sorted_by_x = sorted(dots, key=lambda x: x[0])\n",
    "    \n",
    "#     inter_cell_distances = []\n",
    "#     for i in range(1, len(dots_sorted_by_x)):\n",
    "#         # Horizontal distance between rightmost dot of one cell and leftmost dot of the next cell\n",
    "#         if abs(dots_sorted_by_x[i][1] - dots_sorted_by_x[i-1][1]) > D_V:  # Not part of the same cell vertically\n",
    "#             inter_cell_distances.append(abs(dots_sorted_by_x[i][0] - dots_sorted_by_x[i-1][0]))\n",
    "    \n",
    "#     C_H = np.mean(inter_cell_distances) if inter_cell_distances else 0\n",
    "    \n",
    "#     return D_V, D_H, C_H\n",
    "\n",
    "\n",
    "# def cluster_braille_dots(dot_coordinates, D_V, D_H, C_H):\n",
    "#     \"\"\"\n",
    "#     Cluster the dots into braille cells based on proximity.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - dot_coordinates: List of (x, y) coordinates of dots.\n",
    "#     - D_V: Vertical distance between dots within a cell.\n",
    "#     - D_H: Horizontal distance between dots within a cell.\n",
    "#     - C_H: Horizontal distance between cells.\n",
    "    \n",
    "#     Returns:\n",
    "#     - cells: List of clusters, each representing a braille cell.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Use DBSCAN clustering to group the dots into cells\n",
    "#     X = np.array(dot_coordinates)\n",
    "    \n",
    "#     # Calculate maximum distances between dots for clustering\n",
    "#     max_distance = max(D_H * 2, D_V * 3)  # Max allowed distance between dots in one cell\n",
    "    \n",
    "#     # Apply DBSCAN clustering\n",
    "#     dbscan = DBSCAN(eps=max_distance, min_samples=1)\n",
    "#     labels = dbscan.fit_predict(X)\n",
    "    \n",
    "#     # Group dots by cluster labels (cells)\n",
    "#     cells = {}\n",
    "#     for i, label in enumerate(labels):\n",
    "#         if label not in cells:\n",
    "#             cells[label] = []\n",
    "#         cells[label].append(X[i])\n",
    "    \n",
    "#     return list(cells.values())\n",
    "\n",
    "# def normalize_and_extract_features(cells, D_V, D_H):\n",
    "#     \"\"\"\n",
    "#     Normalize each cell to have consistent coordinates for the six dot positions and \n",
    "#     return the coordinates of dots within each cell.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - cells: List of clusters, each representing a braille cell (set of coordinates).\n",
    "#     - D_V: Vertical distance between dots within a cell.\n",
    "#     - D_H: Horizontal distance between dots within a cell.\n",
    "    \n",
    "#     Returns:\n",
    "#     - normalized_cells: List of normalized cells with coordinates for dots.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     normalized_cells = []\n",
    "    \n",
    "#     for cell in cells:\n",
    "#         # Initialize the six positions (dots 1-6) with coordinates (or None if not present)\n",
    "#         cell_coordinates = [None, None, None, None, None, None]  # [dot1, dot2, dot3, dot4, dot5, dot6]\n",
    "        \n",
    "#         # Find the bounding box of the cell (min_x, min_y) to (max_x, max_y)\n",
    "#         min_x = min([dot[0] for dot in cell])\n",
    "#         min_y = min([dot[1] for dot in cell])\n",
    "#         max_x = max([dot[0] for dot in cell])\n",
    "#         max_y = max([dot[1] for dot in cell])\n",
    "        \n",
    "#         # Normalize positions to fit in the 6-dot braille cell grid\n",
    "#         for dot in cell:\n",
    "#             x, y = dot\n",
    "#             if y - min_y < D_V:\n",
    "#                 if x - min_x < D_H:\n",
    "#                     cell_coordinates[0] = dot  # Dot 1\n",
    "#                 elif x - min_x < 2 * D_H:\n",
    "#                     cell_coordinates[1] = dot  # Dot 2\n",
    "#                 else:\n",
    "#                     cell_coordinates[2] = dot  # Dot 3\n",
    "#             elif y - min_y < 2 * D_V:\n",
    "#                 if x - min_x < D_H:\n",
    "#                     cell_coordinates[3] = dot  # Dot 4\n",
    "#                 elif x - min_x < 2 * D_H:\n",
    "#                     cell_coordinates[4] = dot  # Dot 5\n",
    "#                 else:\n",
    "#                     cell_coordinates[5] = dot  # Dot 6\n",
    "        \n",
    "#         normalized_cells.append(cell_coordinates)\n",
    "    \n",
    "#     return normalized_cells\n",
    "\n",
    "# def draw_bounding_boxes(image, cells, D_V, D_H):\n",
    "#     \"\"\"\n",
    "#     Draw bounding boxes around each identified braille cell.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - image: The input image (OpenCV format).\n",
    "#     - cells: List of clusters, each representing a braille cell (set of coordinates).\n",
    "#     - D_V: Vertical distance between dots within a cell.\n",
    "#     - D_H: Horizontal distance between dots within a cell.\n",
    "    \n",
    "#     Returns:\n",
    "#     - image_with_boxes: Image with bounding boxes drawn around each braille cell.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     image_with_boxes = image.copy()\n",
    "    \n",
    "#     for idx, cell in enumerate(cells):\n",
    "#         # Find the valid dots (coordinates) in the current braille cell\n",
    "#         valid_dots = [dot for dot in cell if dot is not None]\n",
    "        \n",
    "#         if valid_dots:\n",
    "#             # Calculate the bounding box for the current braille cell\n",
    "#             min_x = min([dot[0] for dot in valid_dots])\n",
    "#             min_y = min([dot[1] for dot in valid_dots])\n",
    "#             max_x = max([dot[0] for dot in valid_dots])\n",
    "#             max_y = max([dot[1] for dot in valid_dots])\n",
    "\n",
    "#             # Debugging: print values of the bounding box coordinates\n",
    "#             print(f\"Cell {idx}: min_x = {min_x}, min_y = {min_y}, max_x = {max_x}, max_y = {max_y}\")\n",
    "\n",
    "#             # Check if the values are valid integers and inside image bounds\n",
    "#             if isinstance(min_x, int) and isinstance(min_y, int) and isinstance(max_x, int) and isinstance(max_y, int):\n",
    "#                 # Draw a rectangle (bounding box) around the braille cell\n",
    "#                 cv2.rectangle(image_with_boxes, (min_x, min_y), (max_x, max_y), (0, 255, 0), 2)\n",
    "#             else:\n",
    "#                 print(f\"Invalid bounding box coordinates: min_x={min_x}, min_y={min_y}, max_x={max_x}, max_y={max_y}\")\n",
    "    \n",
    "#     return image_with_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Usage\n",
    "# D_V, D_H, C_H = calculate_distances(dots)\n",
    "# cells = cluster_braille_dots(dots,D_V,D_H,C_H)\n",
    "# normalized_cells=normalize_and_extract_features(cells,D_V,D_H)\n",
    "# op= draw_bounding_boxes(output_image,normalized_cells, D_V, D_H)\n",
    "# cv2.imshow(\"Image with Boxes\", op)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c503e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Step 1: Normalize Y positions into 3 row levels ---\n",
    "# def normalize_rows(centers, tolerance=3):\n",
    "#     \"\"\"\n",
    "#     Normalize rows of Braille dots based on their y-coordinates. This function includes a tolerance \n",
    "#     to treat closely spaced dots as part of the same row, even if their gap is smaller than the median gap.\n",
    "\n",
    "#     Args:\n",
    "#         centers (np.ndarray): 2D array of dot centroids with shape (N, 2), where N is the number of dots.\n",
    "#         tolerance (float): Maximum allowed y-gap between two dots to be considered part of the same row.\n",
    "    \n",
    "#     Returns:\n",
    "#         row_levels (list): List of normalized row levels (y-values) that correspond to the rows of Braille dots.\n",
    "#     \"\"\"\n",
    "#     ys = np.sort(centers[:, 1])  # Sort by y-coordinate (vertical positions of dots)\n",
    "#     y_gaps = np.diff(ys)  # Calculate the differences between consecutive y-values\n",
    "    \n",
    "#     # Calculate the median y-gap as the threshold for row separation\n",
    "#     threshold = np.percentile(y_gaps, 50)\n",
    "    \n",
    "#     row_levels = []\n",
    "#     temp = [ys[0]]\n",
    "    \n",
    "#     for i, d in enumerate(y_gaps):\n",
    "#         if d > threshold and d > tolerance:  # Check for large gap or if gap exceeds tolerance\n",
    "#             row_levels.append(np.mean(temp))  # Add the mean of the previous row\n",
    "#             temp = [ys[i + 1]]  # Start a new row\n",
    "#         else:\n",
    "#             temp.append(ys[i + 1])  # Continue adding dots to the same row\n",
    "    \n",
    "#     # Add the last row (mean of the last group of y-values)\n",
    "#     row_levels.append(np.mean(temp))\n",
    "#     return sorted(row_levels)\n",
    "\n",
    "# def plot_row_lines_on_image(image, centers):\n",
    "#     \"\"\"\n",
    "#     Plots row lines on the input image at the y-positions determined by the normalize_rows function.\n",
    "#     The row lines are drawn in red.\n",
    "\n",
    "#     Args:\n",
    "#         image (np.ndarray): The image on which to draw the row lines.\n",
    "#         centers (np.ndarray): 2D array of dot centroids with shape (N, 2).\n",
    "#         tolerance (float): Maximum allowed y-gap between two dots to be considered part of the same row.\n",
    "    \n",
    "#     Returns:\n",
    "#         np.ndarray: Image with the row lines plotted in red.\n",
    "#     \"\"\"\n",
    "#     # Step 1: Normalize the y-positions of the centers to determine row levels\n",
    "#     row_levels = normalize_rows(centers)\n",
    "    \n",
    "#     # Step 2: Draw horizontal red lines on the image at the row levels\n",
    "#     for row in row_levels:\n",
    "#         # Draw a red horizontal line at y = row\n",
    "#         cv2.line(image, (0, int(row)), (image.shape[1], int(row)), (0, 0, 255), 2)  # Red color in BGR\n",
    "    \n",
    "#     return image\n",
    "\n",
    "# # output_image = plot_row_lines_on_image(img, dots)\n",
    "\n",
    "# # Show the resulting image\n",
    "# # cv2.imshow('Image with Row Lines', output_image)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate pairwise Euclidean distances\n",
    "# pairwise_distances = cdist(dots, dots, metric='euclidean')\n",
    "# # Calculate all pairwise x and y differences\n",
    "# x_diffs = np.abs(dots[:, 0][:, None] - dots[:, 0])\n",
    "# y_diffs = np.abs(dots[:, 1][:, None] - dots[:, 1])\n",
    "\n",
    "# # Exclude zero distances (self-comparisons)\n",
    "# nonzero_x = x_diffs[x_diffs > 0]\n",
    "# nonzero_y = y_diffs[y_diffs > 0]\n",
    "\n",
    "# min_x, max_x = nonzero_x.min(), nonzero_x.max()\n",
    "# min_y, max_y = nonzero_y.min(), nonzero_y.max()\n",
    "\n",
    "# print(f\"Minimum horizontal (x) distance: {min_x:.3f}\")\n",
    "# print(f\"Maximum horizontal (x) distance: {max_x:.3f}\")\n",
    "# print(f\"Minimum vertical (y) distance: {min_y:.3f}\")\n",
    "# print(f\"Maximum vertical (y) distance: {max_y:.3f}\")\n",
    "\n",
    "\n",
    "# def kmeans_clusters(dots, n_clusters=6, image=None, show_centers=False):\n",
    "#     \"\"\"\n",
    "#     Apply K-means clustering to Braille dot centroids and visualize results using OpenCV.\n",
    "    \n",
    "#     Args:\n",
    "#         dots: np.ndarray of shape (N, 2)\n",
    "#         n_clusters: int â€“ number of K-means clusters\n",
    "#         image: optional grayscale or BGR background image\n",
    "#         show_centers: bool â€“ whether to draw yellow cluster centers\n",
    "#     \"\"\"\n",
    "#     if len(dots) == 0:\n",
    "#         print(\"No dots provided.\")\n",
    "#         return\n",
    "    \n",
    "#     # --- 1ï¸âƒ£ Run K-means clustering\n",
    "#     kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "#     labels = kmeans.fit_predict(dots)\n",
    "\n",
    "#     # --- 2ï¸âƒ£ Prepare visualization canvas\n",
    "#     if image is not None:\n",
    "#         vis = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) if len(image.shape) == 2 else image.copy()\n",
    "#     else:\n",
    "#         w = int(np.max(dots[:,0]) + 20)\n",
    "#         h = int(np.max(dots[:,1]) + 20)\n",
    "#         vis = np.ones((h, w, 3), dtype=np.uint8) * 30  # dark background\n",
    "\n",
    "#     # --- 3ï¸âƒ£ Assign distinct colors per cluster\n",
    "#     rng = np.random.default_rng(42)\n",
    "#     palette = (rng.integers(40, 255, size=(n_clusters, 3))).astype(int)\n",
    "\n",
    "#     # --- 4ï¸âƒ£ Draw each dot by cluster color\n",
    "#     for (x, y), label in zip(dots, labels):\n",
    "#         color = tuple(int(c) for c in palette[label])\n",
    "#         cv2.circle(vis, (int(x), int(y)), 8, color, -1)\n",
    "    \n",
    "#     # --- 4.1ï¸âƒ£ Draw bounding boxes around each cluster\n",
    "#     for label in range(n_clusters):\n",
    "#         cluster_points = dots[labels == label]\n",
    "#         if len(cluster_points) == 0:\n",
    "#             continue\n",
    "#         x1, y1 = np.min(cluster_points, axis=0).astype(int)\n",
    "#         x2, y2 = np.max(cluster_points, axis=0).astype(int)\n",
    "#         # cv2.rectangle(vis, (x1-15, y1-15), (x2+15, y2+15), (0, 255, 0), 2)\n",
    "#         # print(123)\n",
    "#         # cropped_image = vis[y1-15:y2+15, x1-15:x2+15]\n",
    "#         # img_gray_loop = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "#         # preprocessed_loop = preprocess_braille_image(img_gray_loop, method=\"sauvola\")\n",
    "#         # binary_loop = consolidate_braille_dots(preprocessed_loop)\n",
    "#         # dots_loop = detect_braille_dots(binary_loop, method=\"connected\", min_area=25, max_area=220)\n",
    "#         # bit_vectors, row_levels, col_gap, cells = process_braille(cluster_points)\n",
    "#         # visualize_braille_segmentation(image, cluster_points, row_levels, cells, col_gap)        \n",
    "\n",
    "#     # --- 5ï¸âƒ£ Optionally draw cluster centers\n",
    "#     if show_centers:\n",
    "#         for (cx, cy) in kmeans.cluster_centers_:\n",
    "#             cv2.drawMarker(vis, (int(cx), int(cy)), (0, 255, 255),\n",
    "#                            markerType=cv2.MARKER_CROSS, markerSize=14, thickness=2)\n",
    "\n",
    "#     # --- 6ï¸âƒ£ Show image\n",
    "#     # cv2.imshow(f\"K-means ({n_clusters} clusters)\", vis)\n",
    "#     # cv2.waitKey(0)\n",
    "#     # cv2.destroyAllWindows()\n",
    "#     cv2.imwrite(\"braille_page_output_6.jpg\",vis)\n",
    "\n",
    "#     return labels\n",
    "\n",
    "\n",
    "# labels = kmeans_clusters(dots, n_clusters=6, image=img)\n",
    "# for i, lbl in enumerate(labels):\n",
    "#     print(f\"Dot {i+1}: Cluster {lbl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c836547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will use for next steps\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# def localized_kmeans_clustering(dots, image=None, show=True):\n",
    "#     \"\"\"\n",
    "#     Cluster Braille dots into local groups (cells) using DBSCAN + localized KMeans.\n",
    "#     Ensures KMeans only runs on close dots (prevents cross-letter mixing).\n",
    "#     \"\"\"\n",
    "#     if len(dots) == 0:\n",
    "#         print(\"No dots provided.\")\n",
    "#         return []\n",
    "\n",
    "#     dots = np.array(dots, dtype=np.float32)\n",
    "\n",
    "#     # --- Step 1ï¸âƒ£: Estimate typical spacing\n",
    "#     xs, ys = dots[:, 0], dots[:, 1]\n",
    "#     dx = np.median(np.diff(np.sort(xs))) if len(xs) > 1 else 10\n",
    "#     dy = np.median(np.diff(np.sort(ys))) if len(ys) > 1 else 10\n",
    "#     eps = np.mean([dx, dy]) * 40  # local region size\n",
    "\n",
    "#     # --- Step 2ï¸âƒ£: Use DBSCAN to find local neighborhoods\n",
    "#     y_scale=2\n",
    "#     dots_scaled = dots.copy()\n",
    "#     dots_scaled[:, 1] *= y_scale\n",
    "#     db = DBSCAN(eps=eps, min_samples=1).fit(dots_scaled)\n",
    "#     labels = db.labels_\n",
    "\n",
    "#     cell_clusters = []\n",
    "#     for lbl in sorted(set(labels)):\n",
    "#         cluster_pts = dots[labels == lbl]\n",
    "#         if len(cluster_pts) == 0:\n",
    "#             continue\n",
    "\n",
    "#         # --- Step 3ï¸âƒ£: Run KMeans *locally* only if >6 dots\n",
    "#         if len(cluster_pts) > 6:\n",
    "#             n_sub = int(np.ceil(len(cluster_pts) / 6))\n",
    "#             kmeans = KMeans(n_clusters=n_sub, random_state=42, n_init=10)\n",
    "#             sub_labels = kmeans.fit_predict(cluster_pts)\n",
    "#             for sub_lbl in np.unique(sub_labels):\n",
    "#                 pts = cluster_pts[sub_labels == sub_lbl]\n",
    "#                 cell_clusters.append(pts)\n",
    "#         else:\n",
    "#             cell_clusters.append(cluster_pts)\n",
    "\n",
    "#     # --- Step 4ï¸âƒ£: Visualization (optional)\n",
    "#     if show:\n",
    "#         if image is not None:\n",
    "#             vis = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) if len(image.shape)==2 else image.copy()\n",
    "#         else:\n",
    "#             w, h = int(np.max(xs) + 20), int(np.max(ys) + 20)\n",
    "#             vis = np.ones((h, w, 3), np.uint8) * 30\n",
    "\n",
    "#         rng = np.random.default_rng(42)\n",
    "#         colors = rng.integers(60, 255, (len(cell_clusters), 3))\n",
    "\n",
    "#         for i, cluster in enumerate(cell_clusters):\n",
    "#             color = tuple(int(c) for c in colors[i])\n",
    "#             for (x, y) in cluster:\n",
    "#                 cv2.circle(vis, (int(x), int(y)), 7, color, -1)\n",
    "\n",
    "#             x1, y1 = np.min(cluster, axis=0).astype(int)\n",
    "#             x2, y2 = np.max(cluster, axis=0).astype(int)\n",
    "#             cv2.rectangle(vis, (x1-4, y1-4), (x2+4, y2+4), color, 2)\n",
    "        \n",
    "#         # Draw bounding boxes for each cluster\n",
    "#         for cluster in cell_clusters:\n",
    "#             x1, y1 = np.min(cluster, axis=0).astype(int)\n",
    "#             x2, y2 = np.max(cluster, axis=0).astype(int)\n",
    "#             cv2.rectangle(vis, (x1-3, y1-3), (x2+3, y2+3), (0, 255, 0), 2)\n",
    "\n",
    "#         cv2.imshow(\"Localized KMeans Clustering\", vis)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#     return cell_clusters\n",
    "\n",
    "# cells = localized_kmeans_clustering(dots, image=output_image)\n",
    "# print(f\"Detected {len(cells)} Braille cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35991f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will use for next steps\n",
    "\n",
    "# import numpy as np\n",
    "# from scipy.spatial.distance import pdist\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# import cv2\n",
    "\n",
    "# def reconstruct_braille_cell(centroids, visualize=True, image=None):\n",
    "#     \"\"\"\n",
    "#     Reconstruct a Braille cell from dot centroids using geometric normalization + ML (KNN).\n",
    "    \n",
    "#     Args:\n",
    "#         centroids : np.ndarray of shape (N, 2) â€“ detected dot centers\n",
    "#         visualize : bool â€“ whether to visualize on OpenCV image\n",
    "#         image     : optional image (grayscale or BGR) for overlay\n",
    "    \n",
    "#     Returns:\n",
    "#         mat        : 3Ã—2 np.uint8 matrix (1 = dot present, 0 = absent)\n",
    "#         positions  : list of predicted Braille dot indices (1â€“6)\n",
    "#     \"\"\"\n",
    "#     if centroids is None or len(centroids) == 0:\n",
    "#         print(\"No centroids provided.\")\n",
    "#         return np.zeros((3,2), dtype=np.uint8), []\n",
    "\n",
    "#     centroids = np.array(centroids, dtype=np.float32)\n",
    "\n",
    "#     # --- Step 1ï¸âƒ£: Estimate scale (d_unit)\n",
    "#     if len(centroids) > 1:\n",
    "#         D = pdist(centroids)\n",
    "#         d_unit = np.median(D)\n",
    "#     else:\n",
    "#         d_unit = 1.0  # fallback for single dot\n",
    "\n",
    "#     # --- Step 2ï¸âƒ£: Normalize coordinate space\n",
    "#     centroids_norm = centroids - centroids.min(axis=0)\n",
    "#     centroids_norm /= (d_unit + 1e-6)\n",
    "\n",
    "#     # --- Step 3ï¸âƒ£: KNN classifier for canonical Braille layout\n",
    "#     X_train = np.array([\n",
    "#         [0.0, 0.0], [0.0, 1.0], [0.0, 2.0],      # left column dots 1â€“3\n",
    "#         [1.6, 0.0], [1.6, 1.0], [1.6, 2.0]       # right column dots 4â€“6\n",
    "#     ])\n",
    "#     y_train = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "#     knn = KNeighborsClassifier(n_neighbors=1)\n",
    "#     knn.fit(X_train, y_train)\n",
    "\n",
    "#     positions = knn.predict(centroids_norm)\n",
    "\n",
    "#     # --- Step 4ï¸âƒ£: Form 2Ã—3 Braille matrix\n",
    "#     mat = np.zeros((3, 2), dtype=np.uint8)\n",
    "#     mapping = {1:(0,0), 2:(1,0), 3:(2,0), 4:(0,1), 5:(1,1), 6:(2,1)}\n",
    "#     for p in positions:\n",
    "#         r, c = mapping[p]\n",
    "#         mat[r, c] = 1\n",
    "\n",
    "#     # --- Optional visualization\n",
    "#     if visualize:\n",
    "#         if image is not None:\n",
    "#             vis = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) if len(image.shape)==2 else image.copy()\n",
    "#         else:\n",
    "#             w = int(np.max(centroids[:,0]) + 40)\n",
    "#             h = int(np.max(centroids[:,1]) + 40)\n",
    "#             vis = np.ones((h, w, 3), np.uint8) * 40\n",
    "\n",
    "#         # Draw dots\n",
    "#         for (x, y), p in zip(centroids, positions):\n",
    "#             cv2.circle(vis, (int(x), int(y)), 8, (0, 255, 255), -1)\n",
    "#             cv2.putText(vis, str(p), (int(x)+10, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "#                         0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#         # Bounding box\n",
    "#         x1, y1 = np.min(centroids, axis=0).astype(int)\n",
    "#         x2, y2 = np.max(centroids, axis=0).astype(int)\n",
    "#         cv2.rectangle(vis, (x1-5, y1-5), (x2+5, y2+5), (0, 200, 0), 2)\n",
    "\n",
    "#         cv2.imshow(\"Braille Cell Reconstruction\", vis)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#     return mat, positions\n",
    "\n",
    "\n",
    "# # --- ðŸ§© Example usage ---\n",
    "# # Simulate a Braille cell (slightly skewed, missing dots possible)\n",
    "\n",
    "# mat, pos = reconstruct_braille_cell(dots, visualize=True, image=img)\n",
    "\n",
    "# print(\"\\nPredicted dot positions (1â€“6):\", pos)\n",
    "# print(\"\\nBraille Matrix (3x2):\\n\", mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cluster_and_visualize_braille(centroids):\n",
    "#     # Assume centroids is a list of [x, y] lists or array\n",
    "#     centroids = np.array(centroids)\n",
    "    \n",
    "#     # Sort by Y (top to bottom)\n",
    "#     centroids = centroids[np.argsort(centroids[:, 1])]\n",
    "    \n",
    "#     # Compute median vertical and horizontal spacings\n",
    "#     y_diffs = np.abs(np.diff(np.sort(centroids[:, 1])))\n",
    "#     dy = np.median(y_diffs[y_diffs > 0]) if np.any(y_diffs > 0) else 1.0  # Fallback to avoid zero\n",
    "    \n",
    "#     x_diffs = np.abs(np.diff(np.sort(centroids[:, 0])))\n",
    "#     dx = np.median(x_diffs[x_diffs > 0]) if np.any(x_diffs > 0) else 1.0  # Fallback to avoid zero\n",
    "    \n",
    "#     # Tolerance for slight tilt (3%)\n",
    "#     tolerance = 1.2\n",
    "    \n",
    "#     # Thresholds with tolerance\n",
    "#     vertical_thresh = dy * 1.1 * tolerance  # Adjusted for same column / vertical closeness\n",
    "#     horizontal_thresh = dy * 3.5 * tolerance  # Adjusted for horizontal gap between cells\n",
    "    \n",
    "#     # Row grouping: group dots into text lines using vertical threshold * 3 with tolerance\n",
    "#     line_thresh = vertical_thresh * 5 * tolerance  # Increased for potential tilt variation\n",
    "#     rows = []\n",
    "#     for dot in centroids:\n",
    "#         added = False\n",
    "#         for row in rows:\n",
    "#             if abs(row['mean_y'] - dot[1]) < line_thresh:\n",
    "#                 row['dots'].append(dot)\n",
    "#                 row['mean_y'] = np.mean([d[1] for d in row['dots']])\n",
    "#                 added = True\n",
    "#                 break\n",
    "#         if not added:\n",
    "#             rows.append({'dots': [dot], 'mean_y': dot[1]})\n",
    "    \n",
    "#     # For each row, sort dots by x and group into cells\n",
    "#     all_cells = []\n",
    "#     for row in rows:\n",
    "#         # Sort dots in row by x (left to right)\n",
    "#         row['dots'] = sorted(row['dots'], key=lambda d: d[0])\n",
    "        \n",
    "#         # Group into cells based on horizontal gaps\n",
    "#         cells = []\n",
    "#         if len(row['dots']) > 0:\n",
    "#             current = [row['dots'][0]]\n",
    "#             for i in range(1, len(row['dots'])):\n",
    "#                 if abs(row['dots'][i][0] - row['dots'][i-1][0]) < horizontal_thresh:\n",
    "#                     current.append(row['dots'][i])\n",
    "#                 else:\n",
    "#                     if len(current) <= 6:  # Braille cell <=6 dots\n",
    "#                         cells.append(current)\n",
    "#                     current = [row['dots'][i]]\n",
    "#             if len(current) <= 6:\n",
    "#                 cells.append(current)\n",
    "#         row['cells'] = cells\n",
    "#         all_cells.extend(cells)\n",
    "    \n",
    "#     # Visualization with OpenCV\n",
    "#     if len(centroids) == 0:\n",
    "#         print(\"No centroids provided.\")\n",
    "#         return\n",
    "    \n",
    "#     min_x = np.min(centroids[:, 0])\n",
    "#     max_x = np.max(centroids[:, 0])\n",
    "#     min_y = np.min(centroids[:, 1])\n",
    "#     max_y = np.max(centroids[:, 1])\n",
    "    \n",
    "#     # Create blank image with padding\n",
    "#     padding = 50\n",
    "#     width = int(max_x - min_x + 2 * padding)\n",
    "#     height = int(max_y - min_y + 2 * padding)\n",
    "#     img = np.ones((height, width, 3), np.uint8) * 255  # White background\n",
    "    \n",
    "#     # Draw dots (shifted)\n",
    "#     dot_radius = 5\n",
    "#     for dot in centroids:\n",
    "#         x_sh = int(dot[0] - min_x + padding)\n",
    "#         y_sh = int(dot[1] - min_y + padding)\n",
    "#         cv2.circle(img, (x_sh, y_sh), dot_radius, (0, 0, 255), -1)  # Red dots\n",
    "    \n",
    "#     # Draw bounding boxes around cells\n",
    "#     box_padding = 10\n",
    "#     for cell in all_cells:\n",
    "#         if len(cell) > 0:\n",
    "#             cell_arr = np.array(cell)\n",
    "#             min_cx = np.min(cell_arr[:, 0])\n",
    "#             max_cx = np.max(cell_arr[:, 0])\n",
    "#             min_cy = np.min(cell_arr[:, 1])\n",
    "#             max_cy = np.max(cell_arr[:, 1])\n",
    "            \n",
    "#             x1 = int(min_cx - min_x + padding - box_padding)\n",
    "#             y1 = int(min_cy - min_y + padding - box_padding)\n",
    "#             x2 = int(max_cx - min_x + padding + box_padding)\n",
    "#             y2 = int(max_cy - min_y + padding + box_padding)\n",
    "            \n",
    "#             cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green boxes\n",
    "    \n",
    "#     # Save the image\n",
    "#     cv2.imshow('braille_cells.png', img)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     # print(\"Visualization saved as 'braille_cells.png'\")\n",
    "#     print(f\"Found {len(all_cells)} Braille cells.\")\n",
    "\n",
    "# # Example usage (replace with your centroids)\n",
    "# # sample_centroids = [\n",
    "# #     [10, 10], [30, 10], [10, 30], [30, 30],  # Cell 1\n",
    "# #     [70, 10], [90, 10], [70, 30]  # Cell 2, incomplete\n",
    "# # ]\n",
    "# cluster_and_visualize_braille(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# braille_segment.py\n",
    "\n",
    "# Usage:\n",
    "#     - Provide a list of centroids: list of (x, y) tuples (float or int).\n",
    "#     - Optionally pass an image path to draw boxes on the source image.\n",
    "#     - This script uses OpenCV (cv2) and numpy. sklearn is optional (for DBSCAN fallback).\n",
    "\n",
    "# Outputs:\n",
    "#     - Returns rows/cells structure and saves a visualization image (if visualize=True).\n",
    "# \"\"\"\n",
    "\n",
    "# import math\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# # Optional imports\n",
    "# try:\n",
    "#     from sklearn.cluster import DBSCAN\n",
    "#     SKLEARN_AVAILABLE = True\n",
    "# except Exception:\n",
    "#     SKLEARN_AVAILABLE = False\n",
    "\n",
    "# def deskew_by_pca(pts):\n",
    "#     \"\"\"\n",
    "#     Compute rotation angle from PCA and rotate points to make text horizontal.\n",
    "#     Returns rotated_points (Nx2), angle_radians, rotation_matrix, centroid\n",
    "#     \"\"\"\n",
    "#     pts = np.asarray(pts, dtype=float)\n",
    "#     centroid = pts.mean(axis=0)\n",
    "#     centered = pts - centroid\n",
    "#     # SVD (PCA)\n",
    "#     U, S, Vt = np.linalg.svd(centered, full_matrices=False)\n",
    "#     # first principal component direction:\n",
    "#     pc1 = Vt[0]\n",
    "#     angle = math.atan2(pc1[1], pc1[0])  # angle of major axis wrt x-axis\n",
    "#     # We want rows horizontal -> rotate by -angle if |angle| > small threshold\n",
    "#     c = math.cos(-angle)\n",
    "#     s = math.sin(-angle)\n",
    "#     R = np.array([[c, -s],[s, c]])\n",
    "#     rotated = (centered @ R.T) + centroid\n",
    "#     return rotated, angle, R, centroid\n",
    "\n",
    "# def estimate_spacings(centroids, tolerance_multiplier=1.03):\n",
    "#     \"\"\"\n",
    "#     Robust estimation of vertical (dy) and horizontal (dx) spacing.\n",
    "#     Returns dy, dx (both floats).\n",
    "#     \"\"\"\n",
    "#     pts = np.asarray(centroids, dtype=float)\n",
    "#     ys = np.sort(pts[:,1])\n",
    "#     xs = np.sort(pts[:,0])\n",
    "\n",
    "#     if len(ys) < 2:\n",
    "#         dy = 1.0\n",
    "#     else:\n",
    "#         dy_diffs = np.abs(np.diff(ys))\n",
    "#         # filter out zeros\n",
    "#         dy_diffs = dy_diffs[dy_diffs > 0]\n",
    "#         dy = float(np.median(dy_diffs)) if dy_diffs.size > 0 else max(1.0, np.ptp(ys)/max(1, len(ys)))\n",
    "#     if len(xs) < 2:\n",
    "#         dx = 1.0\n",
    "#     else:\n",
    "#         dx_diffs = np.abs(np.diff(xs))\n",
    "#         dx_diffs = dx_diffs[dx_diffs > 0]\n",
    "#         dx = float(np.median(dx_diffs)) if dx_diffs.size > 0 else max(1.0, np.ptp(xs)/max(1, len(xs)))\n",
    "\n",
    "#     # apply tolerance multiplier (3% as requested)\n",
    "#     dy *= tolerance_multiplier\n",
    "#     dx *= tolerance_multiplier\n",
    "\n",
    "#     return dy, dx\n",
    "\n",
    "# def group_rows(pts, vertical_thresh):\n",
    "#     \"\"\"\n",
    "#     Groups points into rows based on Y proximity.\n",
    "#     Input pts: Nx2 array (x,y)\n",
    "#     Returns list of rows: each row is dict with keys 'dots' (list of (x,y)), 'mean_y'\n",
    "#     \"\"\"\n",
    "#     rows = []\n",
    "#     for dot in pts:\n",
    "#         x,y = float(dot[0]), float(dot[1])\n",
    "#         added = False\n",
    "#         for row in rows:\n",
    "#             if abs(row['mean_y'] - y) < vertical_thresh * 3:   # using the *3 as suggested\n",
    "#                 row['dots'].append((x,y))\n",
    "#                 row['mean_y'] = float(np.mean([d[1] for d in row['dots']]))\n",
    "#                 added = True\n",
    "#                 break\n",
    "#         if not added:\n",
    "#             rows.append({'dots': [(x,y)], 'mean_y': y})\n",
    "#     # sort rows by mean_y (top to bottom)\n",
    "#     rows = sorted(rows, key=lambda r: r['mean_y'])\n",
    "#     return rows\n",
    "\n",
    "# def group_cells_in_row(row, horizontal_thresh):\n",
    "#     \"\"\"\n",
    "#     Given a row dict with 'dots' list (x,y), group into cells left-to-right using horizontal gaps.\n",
    "#     Returns list of cells (each cell is a list of (x,y))\n",
    "#     \"\"\"\n",
    "#     dots = sorted(row['dots'], key=lambda d: d[0])\n",
    "#     if not dots:\n",
    "#         return []\n",
    "#     cells = []\n",
    "#     current = [dots[0]]\n",
    "#     for i in range(1, len(dots)):\n",
    "#         if abs(dots[i][0] - dots[i-1][0]) < horizontal_thresh:\n",
    "#             current.append(dots[i])\n",
    "#         else:\n",
    "#             cells.append(current)\n",
    "#             current = [dots[i]]\n",
    "#     cells.append(current)\n",
    "#     return cells\n",
    "\n",
    "# def fallback_dbscan(pts, eps):\n",
    "#     \"\"\"\n",
    "#     Use DBSCAN on the raw points when row/col heuristics fail.\n",
    "#     Returns list of clusters: each cluster is a list of (x,y)\n",
    "#     \"\"\"\n",
    "#     if not SKLEARN_AVAILABLE:\n",
    "#         # If sklearn not available, return single cluster\n",
    "#         return [list(map(tuple, pts))]\n",
    "#     db = DBSCAN(eps=eps, min_samples=1).fit(pts)\n",
    "#     labels = db.labels_\n",
    "#     clusters = []\n",
    "#     for lbl in sorted(set(labels)):\n",
    "#         cluster_pts = pts[labels == lbl]\n",
    "#         clusters.append([tuple(p) for p in cluster_pts])\n",
    "#     # sort clusters left-to-right by mean x\n",
    "#     clusters = sorted(clusters, key=lambda c: np.mean([p[0] for p in c]))\n",
    "#     return clusters\n",
    "\n",
    "# def make_bounding_box_for_cell(cell, padding):\n",
    "#     \"\"\"\n",
    "#     cell: list of (x,y) points.\n",
    "#     padding: scalar to add to each side.\n",
    "#     Returns (x1,y1,x2,y2) as ints.\n",
    "#     \"\"\"\n",
    "#     arr = np.array(cell)\n",
    "#     x1 = int(np.floor(arr[:,0].min() - padding))\n",
    "#     x2 = int(np.ceil(arr[:,0].max() + padding))\n",
    "#     y1 = int(np.floor(arr[:,1].min() - padding))\n",
    "#     y2 = int(np.ceil(arr[:,1].max() + padding))\n",
    "#     return (x1,y1,x2,y2)\n",
    "\n",
    "# def segment_braille_cells(centroids,\n",
    "#                           image_path=None,\n",
    "#                           visualize=True,\n",
    "#                           deskew=True,\n",
    "#                           tolerance_pct=0.03,\n",
    "#                           dbscan_fallback=True,\n",
    "#                           out_image_path=\"braille_cells_vis.png\"):\n",
    "#     \"\"\"\n",
    "#     Main function.\n",
    "#     centroids: list of (x,y)\n",
    "#     image_path: optional path to original image. If None, a blank canvas is used.\n",
    "#     visualize: whether to write an output image (OpenCV).\n",
    "#     deskew: whether to apply PCA deskew before grouping.\n",
    "#     tolerance_pct: decimal (0.03 -> 3%) applied to thresholds.\n",
    "#     dbscan_fallback: if True and a row grouping looks bad, run DBSCAN.\n",
    "#     Returns: dict with keys:\n",
    "#         - 'rows' : list of rows, each with 'mean_y', 'cells' (list of cell lists)\n",
    "#         - 'cells_bboxes' : list of (x1,y1,x2,y2) in **original coordinate space**\n",
    "#     \"\"\"\n",
    "#     if len(centroids) == 0:\n",
    "#         return {'rows': [], 'cells_bboxes': []}\n",
    "\n",
    "#     # Convert to ndarray\n",
    "#     pts = np.asarray(centroids, dtype=float)\n",
    "\n",
    "#     # Deskew if requested\n",
    "#     rotated_pts = pts.copy()\n",
    "#     angle = 0.0\n",
    "#     R = np.eye(2)\n",
    "#     centroid_for_rot = np.array([0.,0.])\n",
    "#     if deskew:\n",
    "#         rotated_pts, angle, R, centroid_for_rot = deskew_by_pca(pts)\n",
    "#         # if angle is tiny, we still keep it â€” thresholds are tolerant\n",
    "#         # rotated_pts is in same coordinate space but rotated so rows are horizontal\n",
    "\n",
    "#     # Estimate spacings using rotated coords\n",
    "#     tolerance_multiplier = 1.0 + float(tolerance_pct)\n",
    "#     dy, dx = estimate_spacings(rotated_pts, tolerance_multiplier=tolerance_multiplier)\n",
    "#     # According to your heuristics:\n",
    "#     vertical_thresh = dy * 18  # dots within same column\n",
    "#     horizontal_thresh = dy * 8  # gap to next cell\n",
    "\n",
    "#     # Row grouping on rotated coords (so Y alignment is near horizontal)\n",
    "#     rows = group_rows(rotated_pts, vertical_thresh)\n",
    "\n",
    "#     # If rows look suspicious (too few rows or large variance), consider DBSCAN fallback\n",
    "#     # We'll mark suspicious if there is a row where the y-range of its dots > vertical_thresh*4\n",
    "#     suspicious = False\n",
    "#     for row in rows:\n",
    "#         if len(row['dots']) > 1:\n",
    "#             ys = [d[1] for d in row['dots']]\n",
    "#             if (max(ys) - min(ys)) > (vertical_thresh * 4):\n",
    "#                 suspicious = True\n",
    "#                 break\n",
    "\n",
    "#     cells_bboxes = []\n",
    "#     structured_rows = []\n",
    "#     if suspicious and dbscan_fallback:\n",
    "#         # run DBSCAN on rotated points\n",
    "#         eps = dy * 2.2 * tolerance_multiplier\n",
    "#         clusters = fallback_dbscan(rotated_pts, eps=eps)\n",
    "#         # treat each cluster as a cell\n",
    "#         for i, cluster in enumerate(clusters):\n",
    "#             # compute bbox in rotated space, then map back to original space\n",
    "#             padding = dy * 0.6\n",
    "#             bb = make_bounding_box_for_cell(cluster, padding)\n",
    "#             # convert bbox corners back to original using inverse rotation\n",
    "#             x1,y1,x2,y2 = bb\n",
    "#             corners = np.array([[x1,y1],[x2,y2]])\n",
    "#             # undo rotation: rotated_pts = (original - centroid)*R^T + centroid\n",
    "#             # so original = ((rotated - centroid) @ (R.T)^{-1}) + centroid\n",
    "#             # Since R is orthonormal, inverse is R.T\n",
    "#             R_inv = R.T\n",
    "#             orig_corners = ((corners - centroid_for_rot) @ R_inv.T) + centroid_for_rot\n",
    "#             x1o, y1o = orig_corners[0].astype(int)\n",
    "#             x2o, y2o = orig_corners[1].astype(int)\n",
    "#             # normalize\n",
    "#             x1o, x2o = min(x1o,x2o), max(x1o,x2o)\n",
    "#             y1o, y2o = min(y1o,y2o), max(y1o,y2o)\n",
    "#             cells_bboxes.append((x1o, y1o, x2o, y2o))\n",
    "#         # pack into structured_rows as single-row clusters\n",
    "#         structured_rows = []\n",
    "#         for c in clusters:\n",
    "#             structured_rows.append({\n",
    "#                 'mean_y': float(np.mean([p[1] for p in c])),\n",
    "#                 'cells': [c]\n",
    "#             })\n",
    "#     else:\n",
    "#         # Normal geometric grouping\n",
    "#         for row_idx, row in enumerate(rows):\n",
    "#             cells = group_cells_in_row(row, horizontal_thresh)\n",
    "#             structured_rows.append({'mean_y': row['mean_y'], 'cells': cells})\n",
    "#             # compute bboxes (map them back to original coordinate space if deskew used)\n",
    "#             for cell in cells:\n",
    "#                 padding = dy * 0.6\n",
    "#                 bb = make_bounding_box_for_cell(cell, padding)  # in rotated space\n",
    "#                 x1,y1,x2,y2 = bb\n",
    "#                 corners = np.array([[x1,y1],[x2,y2]])\n",
    "#                 # undo rotation if deskew applied\n",
    "#                 if deskew:\n",
    "#                     R_inv = R.T\n",
    "#                     orig_corners = ((corners - centroid_for_rot) @ R_inv.T) + centroid_for_rot\n",
    "#                     x1o, y1o = orig_corners[0].astype(int)\n",
    "#                     x2o, y2o = orig_corners[1].astype(int)\n",
    "#                 else:\n",
    "#                     x1o, y1o, x2o, y2o = int(x1), int(y1), int(x2), int(y2)\n",
    "#                 x1o, x2o = min(x1o,x2o), max(x1o,x2o)\n",
    "#                 y1o, y2o = min(y1o,y2o), max(y1o,y2o)\n",
    "#                 cells_bboxes.append((x1o, y1o, x2o, y2o))\n",
    "\n",
    "#     # Visualization\n",
    "#     if visualize:\n",
    "#         # If an image path is provided, try to load it. Otherwise make blank canvas scaled to points.\n",
    "#         # if image_path:\n",
    "#             # img = cv2.imread(image_path)\n",
    "#         img = image_path\n",
    "#         #     if img is None:\n",
    "#         #         print(\"Warning: failed to load image_path. Creating blank canvas instead.\")\n",
    "#         #         image_path = None\n",
    "#         # if image_path is None:\n",
    "#         #     # create blank white canvas sized to points extents\n",
    "#         #     all_x = pts[:,0]\n",
    "#         #     all_y = pts[:,1]\n",
    "#         #     w = int(max(300, np.ceil(all_x.max() - all_x.min() + 200)))\n",
    "#         #     h = int(max(300, np.ceil(all_y.max() - all_y.min() + 200)))\n",
    "#         #     img = 255 * np.ones((h, w, 3), dtype=np.uint8)\n",
    "#         #     # shift points so they're visible (add padding)\n",
    "#         #     pad_x = int(100 - all_x.min())\n",
    "#         #     pad_y = int(100 - all_y.min())\n",
    "#         #     # also apply to bbox coordinates after creation below by shifting them\n",
    "#         #     shift = (pad_x, pad_y)\n",
    "#         #     shift_needed = True\n",
    "#         # else:\n",
    "#         shift = (0,0)\n",
    "#         shift_needed = False\n",
    "\n",
    "#         # draw original dots for reference (in red)\n",
    "#         for (x,y) in pts:\n",
    "#             cx = int(round(x + shift[0]))\n",
    "#             cy = int(round(y + shift[1]))\n",
    "#             cv2.circle(img, (cx, cy), 3, (0,0,255), -1)  # red dots\n",
    "\n",
    "#         # draw bounding boxes (blue) and label them\n",
    "#         for idx, bbox in enumerate(cells_bboxes):\n",
    "#             x1,y1,x2,y2 = bbox\n",
    "#             x1 += shift[0]; x2 += shift[0]; y1 += shift[1]; y2 += shift[1]\n",
    "#             # clamp\n",
    "#             x1 = max(0, x1); y1 = max(0, y1)\n",
    "#             x2 = min(img.shape[1]-1, x2); y2 = min(img.shape[0]-1, y2)\n",
    "#             cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 2)  # blue box\n",
    "#             cv2.putText(img, f\"{idx+1}\", (x1+3, y1+14), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "#         cv2.imshow(out_image_path, img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "#         print(f\"Visualization written to: {out_image_path}\")\n",
    "\n",
    "#     result = {\n",
    "#         'rows': structured_rows,\n",
    "#         'cells_bboxes': cells_bboxes,\n",
    "#         'dy': dy,\n",
    "#         'dx': dx,\n",
    "#         'angle_radians': angle\n",
    "#     }\n",
    "#     return result\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # ---------- Example usage ----------\n",
    "#     # Replace 'centroids' with your centroid list and optionally set image_path\n",
    "#     # example_centroids = [\n",
    "#     #     # a small mock example: two rows, three cells per row (various dots)\n",
    "#     #     (50, 50), (50, 70), (50, 90),       # first column, three vertical dots\n",
    "#     #     (110, 50), (110, 70),               # second column, two dots\n",
    "#     #     (170, 50), (170, 70), (170, 90),    # third column\n",
    "#     #     (50, 150), (50,170),                # second row first cell\n",
    "#     #     (110,150), (110,170), (110,190),\n",
    "#     #     (170,150),                          # ...\n",
    "#     # ]\n",
    "#     # # If you want to overlay on an actual high-res image of your scanned Braille page, set image_path\n",
    "#     # image_path = None  # e.g., \"scan.jpg\"\n",
    "\n",
    "#     res = segment_braille_cells(dots, image_path=img,\n",
    "#                                 visualize=True, deskew=True,\n",
    "#                                 tolerance_pct=0.03,\n",
    "#                                 dbscan_fallback=True,\n",
    "#                                 out_image_path=\"braille_cells_visualization.png\")\n",
    "\n",
    "#     print(\"Detected cells (bboxes):\")\n",
    "#     for i, bbox in enumerate(res['cells_bboxes'], 1):\n",
    "#         print(f\"  Cell {i}: bbox={bbox}\")\n",
    "#     print(\"dy (estimated vertical spacing):\", res['dy'])\n",
    "#     print(\"angle (radians) used to deskew:\", res['angle_radians'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
