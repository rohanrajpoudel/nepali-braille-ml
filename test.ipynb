{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d67b092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nepali Braille 6-dot encoding map\n",
    "# Dot numbering:\n",
    "# 1 4\n",
    "# 2 5\n",
    "# 3 6\n",
    "\n",
    "def dots_to_bit(dots):\n",
    "    \"\"\"Convert list of active dots (1â€“6) to a 6-bit integer.\"\"\"\n",
    "    val = 0\n",
    "    for d in dots:\n",
    "        val |= 1 << (6 - d)\n",
    "    return val\n",
    "\n",
    "braille_map = {\n",
    "    dots_to_bit([1]): 'à¤…',\n",
    "    dots_to_bit([3, 4, 5]): 'à¤†',\n",
    "    dots_to_bit([2, 4]): 'à¤‡',\n",
    "    dots_to_bit([3, 5]): 'à¤ˆ',\n",
    "    dots_to_bit([1, 3, 6]): 'à¤‰',\n",
    "    dots_to_bit([1, 2, 5, 6]): 'à¤Š',\n",
    "    dots_to_bit([1, 5, 6]): 'à¤‹',\n",
    "    dots_to_bit([1, 5]): 'à¤',\n",
    "    dots_to_bit([3, 4]): 'à¤',\n",
    "    dots_to_bit([1, 3, 5]): 'à¤“',\n",
    "    dots_to_bit([2, 4, 6]): 'à¤”',\n",
    "    dots_to_bit([1, 6]): 'à¤…à¤‚',\n",
    "    dots_to_bit([6]): 'à¤…à¤ƒ',\n",
    "\n",
    "    dots_to_bit([1, 3]): 'à¤•',\n",
    "    dots_to_bit([4, 6]): 'à¤–',\n",
    "    dots_to_bit([1, 2, 4, 5]): 'à¤—',\n",
    "    dots_to_bit([1, 2, 6]): 'à¤˜',\n",
    "    dots_to_bit([3, 4, 6]): 'à¤™',\n",
    "    dots_to_bit([1, 4]): 'à¤š',\n",
    "    dots_to_bit([1, 6]): 'à¤›',\n",
    "    dots_to_bit([2, 4, 5]): 'à¤œ',\n",
    "    dots_to_bit([3, 5, 6]): 'à¤',\n",
    "    dots_to_bit([2, 5]): 'à¤ž',\n",
    "    dots_to_bit([2, 3, 4, 6]): 'à¤Ÿ',\n",
    "    dots_to_bit([2, 4, 5, 6]): 'à¤ ',\n",
    "    dots_to_bit([1, 2, 4, 6]): 'à¤¡',\n",
    "    dots_to_bit([1, 2, 3, 4, 6]): 'à¤¢',\n",
    "    dots_to_bit([3, 4, 5, 6]): 'à¤£',\n",
    "    dots_to_bit([2, 3, 4, 5]): 'à¤¤',\n",
    "    dots_to_bit([1, 4, 5, 6]): 'à¤¥',\n",
    "    dots_to_bit([1, 4, 5]): 'à¤¦',\n",
    "    dots_to_bit([2, 3, 5, 6]): 'à¤§',\n",
    "    dots_to_bit([1, 3, 4, 5]): 'à¤¨',\n",
    "    dots_to_bit([1, 2, 3, 4]): 'à¤ª',\n",
    "    dots_to_bit([2, 3, 5]): 'à¤«',\n",
    "    dots_to_bit([1, 2]): 'à¤¬',\n",
    "    dots_to_bit([4, 5]): 'à¤­',\n",
    "    dots_to_bit([1, 3, 4]): 'à¤®',\n",
    "    dots_to_bit([1, 3, 4, 5, 6]): 'à¤¯',\n",
    "    dots_to_bit([1, 2, 3, 5]): 'à¤°',\n",
    "    dots_to_bit([1, 2, 3]): 'à¤²',\n",
    "    dots_to_bit([1, 2, 3, 6]): 'à¤µ',\n",
    "    dots_to_bit([1, 4, 6]): 'à¤¶',\n",
    "    dots_to_bit([1, 2, 3, 4, 6]): 'à¤·',\n",
    "    dots_to_bit([2, 3, 4]): 'à¤¸',\n",
    "    dots_to_bit([1, 2, 5]): 'à¤¹',\n",
    "    dots_to_bit([1, 2, 3, 4, 5]): 'à¤•à¥à¤·',\n",
    "    dots_to_bit([1, 5, 6]): 'à¤œà¥à¤ž',\n",
    "}\n",
    "\n",
    "# Special compound (multi-cell)\n",
    "braille_map_compound = {\n",
    "    # 'à¤¤à¥à¤°' uses two cells: [5] + [1,2,4,5,6]\n",
    "    (dots_to_bit([5]), dots_to_bit([1, 2, 4, 5, 6])): 'à¤¤à¥à¤°',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "480109cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_braille_image(\n",
    "    img_gray,\n",
    "    method=\"adaptive\",   # \"adaptive\", \"sauvola\", or \"otsu\"\n",
    "    block_size=31,       # for adaptive/local threshold (odd, e.g. 25â€“51)\n",
    "    C=10,                # constant for adaptive/local threshold\n",
    "    morph_open=3,        # kernel size for opening (3â€“7)\n",
    "    morph_close=5,       # kernel size for closing (3â€“7)\n",
    "    apply_tophat=False,  # True if embossing subtle\n",
    "    min_blob_area=5      # small debris threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess Braille grayscale image for dot detection.\n",
    "    Returns binary image (dots = white, background = black).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Step 1: Denoise slightly (optional but helps) ---\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "\n",
    "    # --- Step 2: Binarization ---\n",
    "    if method == \"adaptive\":\n",
    "        bin_img = cv2.adaptiveThreshold(\n",
    "            img_blur, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV,  # invert â†’ dots white on black\n",
    "            block_size, C\n",
    "        )\n",
    "    elif method == \"otsu\":\n",
    "        _, bin_img = cv2.threshold(\n",
    "            img_blur, 0, 255,\n",
    "            cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )\n",
    "    elif method == \"sauvola\":\n",
    "        # Sauvola via scikit-image if available\n",
    "        from skimage.filters import threshold_sauvola\n",
    "        thresh_s = threshold_sauvola(img_blur, window_size=block_size, k=0.2)\n",
    "        bin_img = (img_blur < thresh_s).astype(np.uint8) * 255\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of: adaptive, otsu, sauvola\")\n",
    "\n",
    "    # --- Step 3: Morphological cleanup ---\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_open, morph_open))\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_close, morph_close))\n",
    "\n",
    "    # Opening: remove small noise\n",
    "    cleaned = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    # Closing: fill small holes in dots\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # --- Step 4: Optional top-hat (enhance embossing if faint) ---\n",
    "    if apply_tophat:\n",
    "        kernel_th = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        tophat = cv2.morphologyEx(img_gray, cv2.MORPH_TOPHAT, kernel_th)\n",
    "        cleaned = cv2.bitwise_or(cleaned, (tophat > 0).astype(np.uint8) * 255)\n",
    "\n",
    "    # --- Step 5: Optional small blob removal ---\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned, connectivity=8)\n",
    "    mask = np.zeros_like(cleaned)\n",
    "    for i in range(1, num_labels):  # skip background\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_blob_area:\n",
    "            mask[labels == i] = 255\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2bb51c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "img =cv2.imread('braille_page_2.jpg')\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "preprocessed = preprocess_braille_image(img_gray, method=\"sauvola\")\n",
    "# cv2.imshow('Before', img_gray)\n",
    "# cv2.imshow('Preprocessed', binary)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e895fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_braille_dots(\n",
    "    binary_img,\n",
    "    method=\"connected\",      # \"connected\", \"blob\", or \"log\"\n",
    "    min_area=5,              # adjust based on resolution (~Ï€*r_minÂ²)\n",
    "    max_area=200,            # reject large merged blobs\n",
    "    circularity_thresh=0.6,  # for blob detector\n",
    "    inertia_thresh=0.5,      # for blob detector\n",
    "    log_min_sigma=1,         # for LoG\n",
    "    log_max_sigma=4,\n",
    "    log_num_sigma=10,\n",
    "    log_threshold=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect Braille dot centroids in a preprocessed binary image.\n",
    "    Returns list of (x, y) coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    centroids = []\n",
    "\n",
    "    # --- Option 1: Connected Components ---\n",
    "    if method == \"connected\":\n",
    "        num_labels, labels, stats, ctds = cv2.connectedComponentsWithStats(binary_img, connectivity=8)\n",
    "        for i in range(1, num_labels):  # skip background\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "            if min_area <= area <= max_area:\n",
    "                x, y = ctds[i]\n",
    "                centroids.append((float(x), float(y)))\n",
    "\n",
    "    # --- Option 2: OpenCV SimpleBlobDetector ---\n",
    "    elif method == \"blob\":\n",
    "        params = cv2.SimpleBlobDetector_Params()\n",
    "        params.filterByArea = True\n",
    "        params.minArea = min_area\n",
    "        params.maxArea = max_area\n",
    "        params.filterByCircularity = True\n",
    "        params.minCircularity = circularity_thresh\n",
    "        params.filterByInertia = True\n",
    "        params.minInertiaRatio = inertia_thresh\n",
    "        params.filterByConvexity = False\n",
    "\n",
    "        detector = cv2.SimpleBlobDetector_create(params)\n",
    "        keypoints = detector.detect(binary_img)\n",
    "        centroids = [(kp.pt[0], kp.pt[1]) for kp in keypoints]\n",
    "\n",
    "    # --- Option 3: Laplacian of Gaussian (LoG) ---\n",
    "    elif method == \"log\":\n",
    "        from skimage.feature import blob_log\n",
    "        binary_float = binary_img.astype(np.float32) / 255.0\n",
    "        blobs = blob_log(binary_float,\n",
    "                         min_sigma=log_min_sigma,\n",
    "                         max_sigma=log_max_sigma,\n",
    "                         num_sigma=log_num_sigma,\n",
    "                         threshold=log_threshold)\n",
    "        # Each blob: (y, x, sigma)\n",
    "        centroids = [(float(x), float(y)) for y, x, s in blobs]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"method must be one of: 'connected', 'blob', or 'log'\")\n",
    "\n",
    "    return np.array(centroids, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f24c612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_braille_dots(binary_img):\n",
    "    \"\"\"\n",
    "    Fix broken or irregular Braille dots before centroid detection.\n",
    "    Returns cleaned binary image.\n",
    "    \"\"\"\n",
    "    # Step 1. Close small holes inside each dot\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closed = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # Step 2. Remove small specks between dots\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open)\n",
    "\n",
    "    # Step 3. Optional: smooth edges slightly\n",
    "    blurred = cv2.GaussianBlur(opened, (3, 3), 0)\n",
    "    _, smooth_bin = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return smooth_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "505c17da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dots: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"braille_page_output_1.jpg\",img)\n",
    "binary = consolidate_braille_dots(preprocessed)\n",
    "dots = detect_braille_dots(binary, method=\"connected\", min_area=20, max_area=220)\n",
    "print(\"Detected dots:\", len(dots))\n",
    "for (x, y) in dots:\n",
    "    cv2.circle(img, (int(x), int(y)), 7, (0,0,255), -1)\n",
    "# Store results\n",
    "height, width, channels = img.shape\n",
    "# Create a white image with the same size\n",
    "output_image = np.ones((height, width, channels), dtype=np.uint8) * 255\n",
    "for (x, y) in dots:\n",
    "    cv2.circle(output_image, (int(x), int(y)), 4, (0,0,0), -1)\n",
    "cv2.imwrite(\"braille_page_output_2.jpg\",binary)\n",
    "cv2.imwrite(\"braille_page_output_3.jpg\",img)\n",
    "cv2.imwrite(\"braille_page_output_4.jpg\",output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c0c503e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Normalize Y positions into 3 row levels ---\n",
    "def normalize_rows(centers, tolerance=3):\n",
    "    \"\"\"\n",
    "    Normalize rows of Braille dots based on their y-coordinates. This function includes a tolerance \n",
    "    to treat closely spaced dots as part of the same row, even if their gap is smaller than the median gap.\n",
    "\n",
    "    Args:\n",
    "        centers (np.ndarray): 2D array of dot centroids with shape (N, 2), where N is the number of dots.\n",
    "        tolerance (float): Maximum allowed y-gap between two dots to be considered part of the same row.\n",
    "    \n",
    "    Returns:\n",
    "        row_levels (list): List of normalized row levels (y-values) that correspond to the rows of Braille dots.\n",
    "    \"\"\"\n",
    "    ys = np.sort(centers[:, 1])  # Sort by y-coordinate (vertical positions of dots)\n",
    "    y_gaps = np.diff(ys)  # Calculate the differences between consecutive y-values\n",
    "    \n",
    "    # Calculate the median y-gap as the threshold for row separation\n",
    "    threshold = np.percentile(y_gaps, 50)\n",
    "    \n",
    "    row_levels = []\n",
    "    temp = [ys[0]]\n",
    "    \n",
    "    for i, d in enumerate(y_gaps):\n",
    "        if d > threshold and d > tolerance:  # Check for large gap or if gap exceeds tolerance\n",
    "            row_levels.append(np.mean(temp))  # Add the mean of the previous row\n",
    "            temp = [ys[i + 1]]  # Start a new row\n",
    "        else:\n",
    "            temp.append(ys[i + 1])  # Continue adding dots to the same row\n",
    "    \n",
    "    # Add the last row (mean of the last group of y-values)\n",
    "    row_levels.append(np.mean(temp))\n",
    "    return sorted(row_levels)\n",
    "\n",
    "def plot_row_lines_on_image(image, centers):\n",
    "    \"\"\"\n",
    "    Plots row lines on the input image at the y-positions determined by the normalize_rows function.\n",
    "    The row lines are drawn in red.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The image on which to draw the row lines.\n",
    "        centers (np.ndarray): 2D array of dot centroids with shape (N, 2).\n",
    "        tolerance (float): Maximum allowed y-gap between two dots to be considered part of the same row.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Image with the row lines plotted in red.\n",
    "    \"\"\"\n",
    "    # Step 1: Normalize the y-positions of the centers to determine row levels\n",
    "    row_levels = normalize_rows(centers)\n",
    "    \n",
    "    # Step 2: Draw horizontal red lines on the image at the row levels\n",
    "    for row in row_levels:\n",
    "        # Draw a red horizontal line at y = row\n",
    "        cv2.line(image, (0, int(row)), (image.shape[1], int(row)), (0, 0, 255), 2)  # Red color in BGR\n",
    "    \n",
    "    return image\n",
    "\n",
    "# output_image = plot_row_lines_on_image(img, dots)\n",
    "\n",
    "# Show the resulting image\n",
    "# cv2.imshow('Image with Row Lines', output_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6f95e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum horizontal (x) distance: 0.054\n",
      "Maximum horizontal (x) distance: 995.227\n",
      "Minimum vertical (y) distance: 0.001\n",
      "Maximum vertical (y) distance: 205.956\n",
      "Dot 1: Cluster 4\n",
      "Dot 2: Cluster 0\n",
      "Dot 3: Cluster 0\n",
      "Dot 4: Cluster 2\n",
      "Dot 5: Cluster 2\n",
      "Dot 6: Cluster 4\n",
      "Dot 7: Cluster 3\n",
      "Dot 8: Cluster 0\n",
      "Dot 9: Cluster 4\n",
      "Dot 10: Cluster 4\n",
      "Dot 11: Cluster 3\n",
      "Dot 12: Cluster 3\n",
      "Dot 13: Cluster 5\n",
      "Dot 14: Cluster 5\n",
      "Dot 15: Cluster 2\n",
      "Dot 16: Cluster 3\n",
      "Dot 17: Cluster 0\n",
      "Dot 18: Cluster 0\n",
      "Dot 19: Cluster 2\n",
      "Dot 20: Cluster 2\n",
      "Dot 21: Cluster 4\n",
      "Dot 22: Cluster 3\n",
      "Dot 23: Cluster 5\n",
      "Dot 24: Cluster 5\n",
      "Dot 25: Cluster 0\n",
      "Dot 26: Cluster 0\n",
      "Dot 27: Cluster 0\n",
      "Dot 28: Cluster 0\n",
      "Dot 29: Cluster 3\n",
      "Dot 30: Cluster 4\n",
      "Dot 31: Cluster 5\n",
      "Dot 32: Cluster 0\n",
      "Dot 33: Cluster 2\n",
      "Dot 34: Cluster 2\n",
      "Dot 35: Cluster 3\n",
      "Dot 36: Cluster 0\n",
      "Dot 37: Cluster 4\n",
      "Dot 38: Cluster 3\n",
      "Dot 39: Cluster 4\n",
      "Dot 40: Cluster 1\n",
      "Dot 41: Cluster 1\n",
      "Dot 42: Cluster 1\n",
      "Dot 43: Cluster 1\n",
      "Dot 44: Cluster 1\n",
      "Dot 45: Cluster 1\n",
      "Dot 46: Cluster 1\n",
      "Dot 47: Cluster 1\n",
      "Dot 48: Cluster 1\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "# Calculate pairwise Euclidean distances\n",
    "pairwise_distances = cdist(dots, dots, metric='euclidean')\n",
    "# Calculate all pairwise x and y differences\n",
    "x_diffs = np.abs(dots[:, 0][:, None] - dots[:, 0])\n",
    "y_diffs = np.abs(dots[:, 1][:, None] - dots[:, 1])\n",
    "\n",
    "# Exclude zero distances (self-comparisons)\n",
    "nonzero_x = x_diffs[x_diffs > 0]\n",
    "nonzero_y = y_diffs[y_diffs > 0]\n",
    "\n",
    "min_x, max_x = nonzero_x.min(), nonzero_x.max()\n",
    "min_y, max_y = nonzero_y.min(), nonzero_y.max()\n",
    "\n",
    "print(f\"Minimum horizontal (x) distance: {min_x:.3f}\")\n",
    "print(f\"Maximum horizontal (x) distance: {max_x:.3f}\")\n",
    "print(f\"Minimum vertical (y) distance: {min_y:.3f}\")\n",
    "print(f\"Maximum vertical (y) distance: {max_y:.3f}\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def kmeans_clusters(dots, n_clusters=6, image=None, show_centers=False):\n",
    "    \"\"\"\n",
    "    Apply K-means clustering to Braille dot centroids and visualize results using OpenCV.\n",
    "    \n",
    "    Args:\n",
    "        dots: np.ndarray of shape (N, 2)\n",
    "        n_clusters: int â€“ number of K-means clusters\n",
    "        image: optional grayscale or BGR background image\n",
    "        show_centers: bool â€“ whether to draw yellow cluster centers\n",
    "    \"\"\"\n",
    "    if len(dots) == 0:\n",
    "        print(\"No dots provided.\")\n",
    "        return\n",
    "    \n",
    "    # --- 1ï¸âƒ£ Run K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(dots)\n",
    "\n",
    "    # --- 2ï¸âƒ£ Prepare visualization canvas\n",
    "    if image is not None:\n",
    "        vis = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) if len(image.shape) == 2 else image.copy()\n",
    "    else:\n",
    "        w = int(np.max(dots[:,0]) + 20)\n",
    "        h = int(np.max(dots[:,1]) + 20)\n",
    "        vis = np.ones((h, w, 3), dtype=np.uint8) * 30  # dark background\n",
    "\n",
    "    # --- 3ï¸âƒ£ Assign distinct colors per cluster\n",
    "    rng = np.random.default_rng(42)\n",
    "    palette = (rng.integers(40, 255, size=(n_clusters, 3))).astype(int)\n",
    "\n",
    "    # --- 4ï¸âƒ£ Draw each dot by cluster color\n",
    "    for (x, y), label in zip(dots, labels):\n",
    "        color = tuple(int(c) for c in palette[label])\n",
    "        cv2.circle(vis, (int(x), int(y)), 8, color, -1)\n",
    "    \n",
    "    # --- 4.1ï¸âƒ£ Draw bounding boxes around each cluster\n",
    "    for label in range(n_clusters):\n",
    "        cluster_points = dots[labels == label]\n",
    "        if len(cluster_points) == 0:\n",
    "            continue\n",
    "        x1, y1 = np.min(cluster_points, axis=0).astype(int)\n",
    "        x2, y2 = np.max(cluster_points, axis=0).astype(int)\n",
    "        # cv2.rectangle(vis, (x1-15, y1-15), (x2+15, y2+15), (0, 255, 0), 2)\n",
    "        # print(123)\n",
    "        # cropped_image = vis[y1-15:y2+15, x1-15:x2+15]\n",
    "        # img_gray_loop = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "        # preprocessed_loop = preprocess_braille_image(img_gray_loop, method=\"sauvola\")\n",
    "        # binary_loop = consolidate_braille_dots(preprocessed_loop)\n",
    "        # dots_loop = detect_braille_dots(binary_loop, method=\"connected\", min_area=25, max_area=220)\n",
    "        # bit_vectors, row_levels, col_gap, cells = process_braille(cluster_points)\n",
    "        # visualize_braille_segmentation(image, cluster_points, row_levels, cells, col_gap)        \n",
    "\n",
    "    # --- 5ï¸âƒ£ Optionally draw cluster centers\n",
    "    if show_centers:\n",
    "        for (cx, cy) in kmeans.cluster_centers_:\n",
    "            cv2.drawMarker(vis, (int(cx), int(cy)), (0, 255, 255),\n",
    "                           markerType=cv2.MARKER_CROSS, markerSize=14, thickness=2)\n",
    "\n",
    "    # --- 6ï¸âƒ£ Show image\n",
    "    # cv2.imshow(f\"K-means ({n_clusters} clusters)\", vis)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    cv2.imwrite(\"braille_page_output_6.jpg\",vis)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "labels = kmeans_clusters(dots, n_clusters=6, image=img)\n",
    "for i, lbl in enumerate(labels):\n",
    "    print(f\"Dot {i+1}: Cluster {lbl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0c836547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# def localized_kmeans_clustering(dots, image=None, show=True):\n",
    "#     \"\"\"\n",
    "#     Cluster Braille dots into local groups (cells) using DBSCAN + localized KMeans.\n",
    "#     Ensures KMeans only runs on close dots (prevents cross-letter mixing).\n",
    "#     \"\"\"\n",
    "#     if len(dots) == 0:\n",
    "#         print(\"No dots provided.\")\n",
    "#         return []\n",
    "\n",
    "#     dots = np.array(dots, dtype=np.float32)\n",
    "\n",
    "#     # --- Step 1ï¸âƒ£: Estimate typical spacing\n",
    "#     xs, ys = dots[:, 0], dots[:, 1]\n",
    "#     dx = np.median(np.diff(np.sort(xs))) if len(xs) > 1 else 10\n",
    "#     dy = np.median(np.diff(np.sort(ys))) if len(ys) > 1 else 10\n",
    "#     eps = np.mean([dx, dy]) * 40  # local region size\n",
    "\n",
    "#     # --- Step 2ï¸âƒ£: Use DBSCAN to find local neighborhoods\n",
    "#     y_scale=2\n",
    "#     dots_scaled = dots.copy()\n",
    "#     dots_scaled[:, 1] *= y_scale\n",
    "#     db = DBSCAN(eps=eps, min_samples=1).fit(dots_scaled)\n",
    "#     labels = db.labels_\n",
    "\n",
    "#     cell_clusters = []\n",
    "#     for lbl in sorted(set(labels)):\n",
    "#         cluster_pts = dots[labels == lbl]\n",
    "#         if len(cluster_pts) == 0:\n",
    "#             continue\n",
    "\n",
    "#         # --- Step 3ï¸âƒ£: Run KMeans *locally* only if >6 dots\n",
    "#         if len(cluster_pts) > 6:\n",
    "#             n_sub = int(np.ceil(len(cluster_pts) / 6))\n",
    "#             kmeans = KMeans(n_clusters=n_sub, random_state=42, n_init=10)\n",
    "#             sub_labels = kmeans.fit_predict(cluster_pts)\n",
    "#             for sub_lbl in np.unique(sub_labels):\n",
    "#                 pts = cluster_pts[sub_labels == sub_lbl]\n",
    "#                 cell_clusters.append(pts)\n",
    "#         else:\n",
    "#             cell_clusters.append(cluster_pts)\n",
    "\n",
    "#     # --- Step 4ï¸âƒ£: Visualization (optional)\n",
    "#     if show:\n",
    "#         if image is not None:\n",
    "#             vis = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) if len(image.shape)==2 else image.copy()\n",
    "#         else:\n",
    "#             w, h = int(np.max(xs) + 20), int(np.max(ys) + 20)\n",
    "#             vis = np.ones((h, w, 3), np.uint8) * 30\n",
    "\n",
    "#         rng = np.random.default_rng(42)\n",
    "#         colors = rng.integers(60, 255, (len(cell_clusters), 3))\n",
    "\n",
    "#         for i, cluster in enumerate(cell_clusters):\n",
    "#             color = tuple(int(c) for c in colors[i])\n",
    "#             for (x, y) in cluster:\n",
    "#                 cv2.circle(vis, (int(x), int(y)), 7, color, -1)\n",
    "\n",
    "#             x1, y1 = np.min(cluster, axis=0).astype(int)\n",
    "#             x2, y2 = np.max(cluster, axis=0).astype(int)\n",
    "#             cv2.rectangle(vis, (x1-4, y1-4), (x2+4, y2+4), color, 2)\n",
    "        \n",
    "#         # Draw bounding boxes for each cluster\n",
    "#         for cluster in cell_clusters:\n",
    "#             x1, y1 = np.min(cluster, axis=0).astype(int)\n",
    "#             x2, y2 = np.max(cluster, axis=0).astype(int)\n",
    "#             cv2.rectangle(vis, (x1-3, y1-3), (x2+3, y2+3), (0, 255, 0), 2)\n",
    "\n",
    "#         cv2.imshow(\"Localized KMeans Clustering\", vis)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "#     return cell_clusters\n",
    "\n",
    "# cells = localized_kmeans_clustering(dots, image=output_image)\n",
    "# print(f\"Detected {len(cells)} Braille cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f35991f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted dot positions (1â€“6): [1 4 4 4 4 1 1 4 1 1 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 1 4 4 4 4 1 4 1\n",
      " 4 1 1 1 1 1 1 2 2 2 2]\n",
      "\n",
      "Braille Matrix (3x2):\n",
      " [[1 1]\n",
      " [1 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2\n",
    "\n",
    "def reconstruct_braille_cell(centroids, visualize=True, image=None):\n",
    "    \"\"\"\n",
    "    Reconstruct a Braille cell from dot centroids using geometric normalization + ML (KNN).\n",
    "    \n",
    "    Args:\n",
    "        centroids : np.ndarray of shape (N, 2) â€“ detected dot centers\n",
    "        visualize : bool â€“ whether to visualize on OpenCV image\n",
    "        image     : optional image (grayscale or BGR) for overlay\n",
    "    \n",
    "    Returns:\n",
    "        mat        : 3Ã—2 np.uint8 matrix (1 = dot present, 0 = absent)\n",
    "        positions  : list of predicted Braille dot indices (1â€“6)\n",
    "    \"\"\"\n",
    "    if centroids is None or len(centroids) == 0:\n",
    "        print(\"No centroids provided.\")\n",
    "        return np.zeros((3,2), dtype=np.uint8), []\n",
    "\n",
    "    centroids = np.array(centroids, dtype=np.float32)\n",
    "\n",
    "    # --- Step 1ï¸âƒ£: Estimate scale (d_unit)\n",
    "    if len(centroids) > 1:\n",
    "        D = pdist(centroids)\n",
    "        d_unit = np.median(D)\n",
    "    else:\n",
    "        d_unit = 1.0  # fallback for single dot\n",
    "\n",
    "    # --- Step 2ï¸âƒ£: Normalize coordinate space\n",
    "    centroids_norm = centroids - centroids.min(axis=0)\n",
    "    centroids_norm /= (d_unit + 1e-6)\n",
    "\n",
    "    # --- Step 3ï¸âƒ£: KNN classifier for canonical Braille layout\n",
    "    X_train = np.array([\n",
    "        [0.0, 0.0], [0.0, 1.0], [0.0, 2.0],      # left column dots 1â€“3\n",
    "        [1.6, 0.0], [1.6, 1.0], [1.6, 2.0]       # right column dots 4â€“6\n",
    "    ])\n",
    "    y_train = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    positions = knn.predict(centroids_norm)\n",
    "\n",
    "    # --- Step 4ï¸âƒ£: Form 2Ã—3 Braille matrix\n",
    "    mat = np.zeros((3, 2), dtype=np.uint8)\n",
    "    mapping = {1:(0,0), 2:(1,0), 3:(2,0), 4:(0,1), 5:(1,1), 6:(2,1)}\n",
    "    for p in positions:\n",
    "        r, c = mapping[p]\n",
    "        mat[r, c] = 1\n",
    "\n",
    "    # --- Optional visualization\n",
    "    if visualize:\n",
    "        if image is not None:\n",
    "            vis = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR) if len(image.shape)==2 else image.copy()\n",
    "        else:\n",
    "            w = int(np.max(centroids[:,0]) + 40)\n",
    "            h = int(np.max(centroids[:,1]) + 40)\n",
    "            vis = np.ones((h, w, 3), np.uint8) * 40\n",
    "\n",
    "        # Draw dots\n",
    "        for (x, y), p in zip(centroids, positions):\n",
    "            cv2.circle(vis, (int(x), int(y)), 8, (0, 255, 255), -1)\n",
    "            cv2.putText(vis, str(p), (int(x)+10, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Bounding box\n",
    "        x1, y1 = np.min(centroids, axis=0).astype(int)\n",
    "        x2, y2 = np.max(centroids, axis=0).astype(int)\n",
    "        cv2.rectangle(vis, (x1-5, y1-5), (x2+5, y2+5), (0, 200, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Braille Cell Reconstruction\", vis)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return mat, positions\n",
    "\n",
    "\n",
    "# --- ðŸ§© Example usage ---\n",
    "# Simulate a Braille cell (slightly skewed, missing dots possible)\n",
    "\n",
    "mat, pos = reconstruct_braille_cell(dots, visualize=True, image=img)\n",
    "\n",
    "print(\"\\nPredicted dot positions (1â€“6):\", pos)\n",
    "print(\"\\nBraille Matrix (3x2):\\n\", mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7a3c1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 Braille cells.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import cv2\n",
    "\n",
    "def cluster_and_visualize_braille(centroids):\n",
    "    # Assume centroids is a list of [x, y] lists or array\n",
    "    centroids = np.array(centroids)\n",
    "    \n",
    "    # Sort by Y (top to bottom)\n",
    "    centroids = centroids[np.argsort(centroids[:, 1])]\n",
    "    \n",
    "    # Compute median vertical and horizontal spacings\n",
    "    y_diffs = np.abs(np.diff(np.sort(centroids[:, 1])))\n",
    "    dy = np.median(y_diffs[y_diffs > 0]) if np.any(y_diffs > 0) else 1.0  # Fallback to avoid zero\n",
    "    \n",
    "    x_diffs = np.abs(np.diff(np.sort(centroids[:, 0])))\n",
    "    dx = np.median(x_diffs[x_diffs > 0]) if np.any(x_diffs > 0) else 1.0  # Fallback to avoid zero\n",
    "    \n",
    "    # Tolerance for slight tilt (3%)\n",
    "    tolerance = 1.2\n",
    "    \n",
    "    # Thresholds with tolerance\n",
    "    vertical_thresh = dy * 1.1 * tolerance  # Adjusted for same column / vertical closeness\n",
    "    horizontal_thresh = dy * 3.5 * tolerance  # Adjusted for horizontal gap between cells\n",
    "    \n",
    "    # Row grouping: group dots into text lines using vertical threshold * 3 with tolerance\n",
    "    line_thresh = vertical_thresh * 5 * tolerance  # Increased for potential tilt variation\n",
    "    rows = []\n",
    "    for dot in centroids:\n",
    "        added = False\n",
    "        for row in rows:\n",
    "            if abs(row['mean_y'] - dot[1]) < line_thresh:\n",
    "                row['dots'].append(dot)\n",
    "                row['mean_y'] = np.mean([d[1] for d in row['dots']])\n",
    "                added = True\n",
    "                break\n",
    "        if not added:\n",
    "            rows.append({'dots': [dot], 'mean_y': dot[1]})\n",
    "    \n",
    "    # For each row, sort dots by x and group into cells\n",
    "    all_cells = []\n",
    "    for row in rows:\n",
    "        # Sort dots in row by x (left to right)\n",
    "        row['dots'] = sorted(row['dots'], key=lambda d: d[0])\n",
    "        \n",
    "        # Group into cells based on horizontal gaps\n",
    "        cells = []\n",
    "        if len(row['dots']) > 0:\n",
    "            current = [row['dots'][0]]\n",
    "            for i in range(1, len(row['dots'])):\n",
    "                if abs(row['dots'][i][0] - row['dots'][i-1][0]) < horizontal_thresh:\n",
    "                    current.append(row['dots'][i])\n",
    "                else:\n",
    "                    if len(current) <= 6:  # Braille cell <=6 dots\n",
    "                        cells.append(current)\n",
    "                    current = [row['dots'][i]]\n",
    "            if len(current) <= 6:\n",
    "                cells.append(current)\n",
    "        row['cells'] = cells\n",
    "        all_cells.extend(cells)\n",
    "    \n",
    "    # Visualization with OpenCV\n",
    "    if len(centroids) == 0:\n",
    "        print(\"No centroids provided.\")\n",
    "        return\n",
    "    \n",
    "    min_x = np.min(centroids[:, 0])\n",
    "    max_x = np.max(centroids[:, 0])\n",
    "    min_y = np.min(centroids[:, 1])\n",
    "    max_y = np.max(centroids[:, 1])\n",
    "    \n",
    "    # Create blank image with padding\n",
    "    padding = 50\n",
    "    width = int(max_x - min_x + 2 * padding)\n",
    "    height = int(max_y - min_y + 2 * padding)\n",
    "    img = np.ones((height, width, 3), np.uint8) * 255  # White background\n",
    "    \n",
    "    # Draw dots (shifted)\n",
    "    dot_radius = 5\n",
    "    for dot in centroids:\n",
    "        x_sh = int(dot[0] - min_x + padding)\n",
    "        y_sh = int(dot[1] - min_y + padding)\n",
    "        cv2.circle(img, (x_sh, y_sh), dot_radius, (0, 0, 255), -1)  # Red dots\n",
    "    \n",
    "    # Draw bounding boxes around cells\n",
    "    box_padding = 10\n",
    "    for cell in all_cells:\n",
    "        if len(cell) > 0:\n",
    "            cell_arr = np.array(cell)\n",
    "            min_cx = np.min(cell_arr[:, 0])\n",
    "            max_cx = np.max(cell_arr[:, 0])\n",
    "            min_cy = np.min(cell_arr[:, 1])\n",
    "            max_cy = np.max(cell_arr[:, 1])\n",
    "            \n",
    "            x1 = int(min_cx - min_x + padding - box_padding)\n",
    "            y1 = int(min_cy - min_y + padding - box_padding)\n",
    "            x2 = int(max_cx - min_x + padding + box_padding)\n",
    "            y2 = int(max_cy - min_y + padding + box_padding)\n",
    "            \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green boxes\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imshow('braille_cells.png', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # print(\"Visualization saved as 'braille_cells.png'\")\n",
    "    print(f\"Found {len(all_cells)} Braille cells.\")\n",
    "\n",
    "# Example usage (replace with your centroids)\n",
    "# sample_centroids = [\n",
    "#     [10, 10], [30, 10], [10, 30], [30, 30],  # Cell 1\n",
    "#     [70, 10], [90, 10], [70, 30]  # Cell 2, incomplete\n",
    "# ]\n",
    "cluster_and_visualize_braille(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6e01638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization written to: braille_cells_visualization.png\n",
      "Detected cells (bboxes):\n",
      "  Cell 1: bbox=(np.int64(28), np.int64(50), np.int64(75), np.int64(254))\n",
      "  Cell 2: bbox=(np.int64(80), np.int64(50), np.int64(120), np.int64(253))\n",
      "  Cell 3: bbox=(np.int64(129), np.int64(51), np.int64(191), np.int64(251))\n",
      "  Cell 4: bbox=(np.int64(314), np.int64(49), np.int64(326), np.int64(91))\n",
      "  Cell 5: bbox=(np.int64(346), np.int64(49), np.int64(353), np.int64(71))\n",
      "  Cell 6: bbox=(np.int64(394), np.int64(49), np.int64(422), np.int64(89))\n",
      "  Cell 7: bbox=(np.int64(541), np.int64(49), np.int64(549), np.int64(71))\n",
      "  Cell 8: bbox=(np.int64(588), np.int64(49), np.int64(598), np.int64(89))\n",
      "  Cell 9: bbox=(np.int64(733), np.int64(47), np.int64(761), np.int64(88))\n",
      "  Cell 10: bbox=(np.int64(782), np.int64(47), np.int64(808), np.int64(72))\n",
      "  Cell 11: bbox=(np.int64(828), np.int64(48), np.int64(857), np.int64(87))\n",
      "  Cell 12: bbox=(np.int64(973), np.int64(47), np.int64(997), np.int64(89))\n",
      "  Cell 13: bbox=(np.int64(1017), np.int64(46), np.int64(1046), np.int64(87))\n",
      "dy (estimated vertical spacing): 2.984818444726581\n",
      "angle (radians) used to deskew: -0.10199082847981189\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "braille_segment.py\n",
    "\n",
    "Usage:\n",
    "    - Provide a list of centroids: list of (x, y) tuples (float or int).\n",
    "    - Optionally pass an image path to draw boxes on the source image.\n",
    "    - This script uses OpenCV (cv2) and numpy. sklearn is optional (for DBSCAN fallback).\n",
    "\n",
    "Outputs:\n",
    "    - Returns rows/cells structure and saves a visualization image (if visualize=True).\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except Exception:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "\n",
    "def deskew_by_pca(pts):\n",
    "    \"\"\"\n",
    "    Compute rotation angle from PCA and rotate points to make text horizontal.\n",
    "    Returns rotated_points (Nx2), angle_radians, rotation_matrix, centroid\n",
    "    \"\"\"\n",
    "    pts = np.asarray(pts, dtype=float)\n",
    "    centroid = pts.mean(axis=0)\n",
    "    centered = pts - centroid\n",
    "    # SVD (PCA)\n",
    "    U, S, Vt = np.linalg.svd(centered, full_matrices=False)\n",
    "    # first principal component direction:\n",
    "    pc1 = Vt[0]\n",
    "    angle = math.atan2(pc1[1], pc1[0])  # angle of major axis wrt x-axis\n",
    "    # We want rows horizontal -> rotate by -angle if |angle| > small threshold\n",
    "    c = math.cos(-angle)\n",
    "    s = math.sin(-angle)\n",
    "    R = np.array([[c, -s],[s, c]])\n",
    "    rotated = (centered @ R.T) + centroid\n",
    "    return rotated, angle, R, centroid\n",
    "\n",
    "def estimate_spacings(centroids, tolerance_multiplier=1.03):\n",
    "    \"\"\"\n",
    "    Robust estimation of vertical (dy) and horizontal (dx) spacing.\n",
    "    Returns dy, dx (both floats).\n",
    "    \"\"\"\n",
    "    pts = np.asarray(centroids, dtype=float)\n",
    "    ys = np.sort(pts[:,1])\n",
    "    xs = np.sort(pts[:,0])\n",
    "\n",
    "    if len(ys) < 2:\n",
    "        dy = 1.0\n",
    "    else:\n",
    "        dy_diffs = np.abs(np.diff(ys))\n",
    "        # filter out zeros\n",
    "        dy_diffs = dy_diffs[dy_diffs > 0]\n",
    "        dy = float(np.median(dy_diffs)) if dy_diffs.size > 0 else max(1.0, np.ptp(ys)/max(1, len(ys)))\n",
    "    if len(xs) < 2:\n",
    "        dx = 1.0\n",
    "    else:\n",
    "        dx_diffs = np.abs(np.diff(xs))\n",
    "        dx_diffs = dx_diffs[dx_diffs > 0]\n",
    "        dx = float(np.median(dx_diffs)) if dx_diffs.size > 0 else max(1.0, np.ptp(xs)/max(1, len(xs)))\n",
    "\n",
    "    # apply tolerance multiplier (3% as requested)\n",
    "    dy *= tolerance_multiplier\n",
    "    dx *= tolerance_multiplier\n",
    "\n",
    "    return dy, dx\n",
    "\n",
    "def group_rows(pts, vertical_thresh):\n",
    "    \"\"\"\n",
    "    Groups points into rows based on Y proximity.\n",
    "    Input pts: Nx2 array (x,y)\n",
    "    Returns list of rows: each row is dict with keys 'dots' (list of (x,y)), 'mean_y'\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for dot in pts:\n",
    "        x,y = float(dot[0]), float(dot[1])\n",
    "        added = False\n",
    "        for row in rows:\n",
    "            if abs(row['mean_y'] - y) < vertical_thresh * 3:   # using the *3 as suggested\n",
    "                row['dots'].append((x,y))\n",
    "                row['mean_y'] = float(np.mean([d[1] for d in row['dots']]))\n",
    "                added = True\n",
    "                break\n",
    "        if not added:\n",
    "            rows.append({'dots': [(x,y)], 'mean_y': y})\n",
    "    # sort rows by mean_y (top to bottom)\n",
    "    rows = sorted(rows, key=lambda r: r['mean_y'])\n",
    "    return rows\n",
    "\n",
    "def group_cells_in_row(row, horizontal_thresh):\n",
    "    \"\"\"\n",
    "    Given a row dict with 'dots' list (x,y), group into cells left-to-right using horizontal gaps.\n",
    "    Returns list of cells (each cell is a list of (x,y))\n",
    "    \"\"\"\n",
    "    dots = sorted(row['dots'], key=lambda d: d[0])\n",
    "    if not dots:\n",
    "        return []\n",
    "    cells = []\n",
    "    current = [dots[0]]\n",
    "    for i in range(1, len(dots)):\n",
    "        if abs(dots[i][0] - dots[i-1][0]) < horizontal_thresh:\n",
    "            current.append(dots[i])\n",
    "        else:\n",
    "            cells.append(current)\n",
    "            current = [dots[i]]\n",
    "    cells.append(current)\n",
    "    return cells\n",
    "\n",
    "def fallback_dbscan(pts, eps):\n",
    "    \"\"\"\n",
    "    Use DBSCAN on the raw points when row/col heuristics fail.\n",
    "    Returns list of clusters: each cluster is a list of (x,y)\n",
    "    \"\"\"\n",
    "    if not SKLEARN_AVAILABLE:\n",
    "        # If sklearn not available, return single cluster\n",
    "        return [list(map(tuple, pts))]\n",
    "    db = DBSCAN(eps=eps, min_samples=1).fit(pts)\n",
    "    labels = db.labels_\n",
    "    clusters = []\n",
    "    for lbl in sorted(set(labels)):\n",
    "        cluster_pts = pts[labels == lbl]\n",
    "        clusters.append([tuple(p) for p in cluster_pts])\n",
    "    # sort clusters left-to-right by mean x\n",
    "    clusters = sorted(clusters, key=lambda c: np.mean([p[0] for p in c]))\n",
    "    return clusters\n",
    "\n",
    "def make_bounding_box_for_cell(cell, padding):\n",
    "    \"\"\"\n",
    "    cell: list of (x,y) points.\n",
    "    padding: scalar to add to each side.\n",
    "    Returns (x1,y1,x2,y2) as ints.\n",
    "    \"\"\"\n",
    "    arr = np.array(cell)\n",
    "    x1 = int(np.floor(arr[:,0].min() - padding))\n",
    "    x2 = int(np.ceil(arr[:,0].max() + padding))\n",
    "    y1 = int(np.floor(arr[:,1].min() - padding))\n",
    "    y2 = int(np.ceil(arr[:,1].max() + padding))\n",
    "    return (x1,y1,x2,y2)\n",
    "\n",
    "def segment_braille_cells(centroids,\n",
    "                          image_path=None,\n",
    "                          visualize=True,\n",
    "                          deskew=True,\n",
    "                          tolerance_pct=0.03,\n",
    "                          dbscan_fallback=True,\n",
    "                          out_image_path=\"braille_cells_vis.png\"):\n",
    "    \"\"\"\n",
    "    Main function.\n",
    "    centroids: list of (x,y)\n",
    "    image_path: optional path to original image. If None, a blank canvas is used.\n",
    "    visualize: whether to write an output image (OpenCV).\n",
    "    deskew: whether to apply PCA deskew before grouping.\n",
    "    tolerance_pct: decimal (0.03 -> 3%) applied to thresholds.\n",
    "    dbscan_fallback: if True and a row grouping looks bad, run DBSCAN.\n",
    "    Returns: dict with keys:\n",
    "        - 'rows' : list of rows, each with 'mean_y', 'cells' (list of cell lists)\n",
    "        - 'cells_bboxes' : list of (x1,y1,x2,y2) in **original coordinate space**\n",
    "    \"\"\"\n",
    "    if len(centroids) == 0:\n",
    "        return {'rows': [], 'cells_bboxes': []}\n",
    "\n",
    "    # Convert to ndarray\n",
    "    pts = np.asarray(centroids, dtype=float)\n",
    "\n",
    "    # Deskew if requested\n",
    "    rotated_pts = pts.copy()\n",
    "    angle = 0.0\n",
    "    R = np.eye(2)\n",
    "    centroid_for_rot = np.array([0.,0.])\n",
    "    if deskew:\n",
    "        rotated_pts, angle, R, centroid_for_rot = deskew_by_pca(pts)\n",
    "        # if angle is tiny, we still keep it â€” thresholds are tolerant\n",
    "        # rotated_pts is in same coordinate space but rotated so rows are horizontal\n",
    "\n",
    "    # Estimate spacings using rotated coords\n",
    "    tolerance_multiplier = 1.0 + float(tolerance_pct)\n",
    "    dy, dx = estimate_spacings(rotated_pts, tolerance_multiplier=tolerance_multiplier)\n",
    "    # According to your heuristics:\n",
    "    vertical_thresh = dy * 18  # dots within same column\n",
    "    horizontal_thresh = dy * 8  # gap to next cell\n",
    "\n",
    "    # Row grouping on rotated coords (so Y alignment is near horizontal)\n",
    "    rows = group_rows(rotated_pts, vertical_thresh)\n",
    "\n",
    "    # If rows look suspicious (too few rows or large variance), consider DBSCAN fallback\n",
    "    # We'll mark suspicious if there is a row where the y-range of its dots > vertical_thresh*4\n",
    "    suspicious = False\n",
    "    for row in rows:\n",
    "        if len(row['dots']) > 1:\n",
    "            ys = [d[1] for d in row['dots']]\n",
    "            if (max(ys) - min(ys)) > (vertical_thresh * 4):\n",
    "                suspicious = True\n",
    "                break\n",
    "\n",
    "    cells_bboxes = []\n",
    "    structured_rows = []\n",
    "    if suspicious and dbscan_fallback:\n",
    "        # run DBSCAN on rotated points\n",
    "        eps = dy * 2.2 * tolerance_multiplier\n",
    "        clusters = fallback_dbscan(rotated_pts, eps=eps)\n",
    "        # treat each cluster as a cell\n",
    "        for i, cluster in enumerate(clusters):\n",
    "            # compute bbox in rotated space, then map back to original space\n",
    "            padding = dy * 0.6\n",
    "            bb = make_bounding_box_for_cell(cluster, padding)\n",
    "            # convert bbox corners back to original using inverse rotation\n",
    "            x1,y1,x2,y2 = bb\n",
    "            corners = np.array([[x1,y1],[x2,y2]])\n",
    "            # undo rotation: rotated_pts = (original - centroid)*R^T + centroid\n",
    "            # so original = ((rotated - centroid) @ (R.T)^{-1}) + centroid\n",
    "            # Since R is orthonormal, inverse is R.T\n",
    "            R_inv = R.T\n",
    "            orig_corners = ((corners - centroid_for_rot) @ R_inv.T) + centroid_for_rot\n",
    "            x1o, y1o = orig_corners[0].astype(int)\n",
    "            x2o, y2o = orig_corners[1].astype(int)\n",
    "            # normalize\n",
    "            x1o, x2o = min(x1o,x2o), max(x1o,x2o)\n",
    "            y1o, y2o = min(y1o,y2o), max(y1o,y2o)\n",
    "            cells_bboxes.append((x1o, y1o, x2o, y2o))\n",
    "        # pack into structured_rows as single-row clusters\n",
    "        structured_rows = []\n",
    "        for c in clusters:\n",
    "            structured_rows.append({\n",
    "                'mean_y': float(np.mean([p[1] for p in c])),\n",
    "                'cells': [c]\n",
    "            })\n",
    "    else:\n",
    "        # Normal geometric grouping\n",
    "        for row_idx, row in enumerate(rows):\n",
    "            cells = group_cells_in_row(row, horizontal_thresh)\n",
    "            structured_rows.append({'mean_y': row['mean_y'], 'cells': cells})\n",
    "            # compute bboxes (map them back to original coordinate space if deskew used)\n",
    "            for cell in cells:\n",
    "                padding = dy * 0.6\n",
    "                bb = make_bounding_box_for_cell(cell, padding)  # in rotated space\n",
    "                x1,y1,x2,y2 = bb\n",
    "                corners = np.array([[x1,y1],[x2,y2]])\n",
    "                # undo rotation if deskew applied\n",
    "                if deskew:\n",
    "                    R_inv = R.T\n",
    "                    orig_corners = ((corners - centroid_for_rot) @ R_inv.T) + centroid_for_rot\n",
    "                    x1o, y1o = orig_corners[0].astype(int)\n",
    "                    x2o, y2o = orig_corners[1].astype(int)\n",
    "                else:\n",
    "                    x1o, y1o, x2o, y2o = int(x1), int(y1), int(x2), int(y2)\n",
    "                x1o, x2o = min(x1o,x2o), max(x1o,x2o)\n",
    "                y1o, y2o = min(y1o,y2o), max(y1o,y2o)\n",
    "                cells_bboxes.append((x1o, y1o, x2o, y2o))\n",
    "\n",
    "    # Visualization\n",
    "    if visualize:\n",
    "        # If an image path is provided, try to load it. Otherwise make blank canvas scaled to points.\n",
    "        # if image_path:\n",
    "            # img = cv2.imread(image_path)\n",
    "        img = image_path\n",
    "        #     if img is None:\n",
    "        #         print(\"Warning: failed to load image_path. Creating blank canvas instead.\")\n",
    "        #         image_path = None\n",
    "        # if image_path is None:\n",
    "        #     # create blank white canvas sized to points extents\n",
    "        #     all_x = pts[:,0]\n",
    "        #     all_y = pts[:,1]\n",
    "        #     w = int(max(300, np.ceil(all_x.max() - all_x.min() + 200)))\n",
    "        #     h = int(max(300, np.ceil(all_y.max() - all_y.min() + 200)))\n",
    "        #     img = 255 * np.ones((h, w, 3), dtype=np.uint8)\n",
    "        #     # shift points so they're visible (add padding)\n",
    "        #     pad_x = int(100 - all_x.min())\n",
    "        #     pad_y = int(100 - all_y.min())\n",
    "        #     # also apply to bbox coordinates after creation below by shifting them\n",
    "        #     shift = (pad_x, pad_y)\n",
    "        #     shift_needed = True\n",
    "        # else:\n",
    "        shift = (0,0)\n",
    "        shift_needed = False\n",
    "\n",
    "        # draw original dots for reference (in red)\n",
    "        for (x,y) in pts:\n",
    "            cx = int(round(x + shift[0]))\n",
    "            cy = int(round(y + shift[1]))\n",
    "            cv2.circle(img, (cx, cy), 3, (0,0,255), -1)  # red dots\n",
    "\n",
    "        # draw bounding boxes (blue) and label them\n",
    "        for idx, bbox in enumerate(cells_bboxes):\n",
    "            x1,y1,x2,y2 = bbox\n",
    "            x1 += shift[0]; x2 += shift[0]; y1 += shift[1]; y2 += shift[1]\n",
    "            # clamp\n",
    "            x1 = max(0, x1); y1 = max(0, y1)\n",
    "            x2 = min(img.shape[1]-1, x2); y2 = min(img.shape[0]-1, y2)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 2)  # blue box\n",
    "            cv2.putText(img, f\"{idx+1}\", (x1+3, y1+14), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(out_image_path, img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Visualization written to: {out_image_path}\")\n",
    "\n",
    "    result = {\n",
    "        'rows': structured_rows,\n",
    "        'cells_bboxes': cells_bboxes,\n",
    "        'dy': dy,\n",
    "        'dx': dx,\n",
    "        'angle_radians': angle\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ---------- Example usage ----------\n",
    "    # Replace 'centroids' with your centroid list and optionally set image_path\n",
    "    # example_centroids = [\n",
    "    #     # a small mock example: two rows, three cells per row (various dots)\n",
    "    #     (50, 50), (50, 70), (50, 90),       # first column, three vertical dots\n",
    "    #     (110, 50), (110, 70),               # second column, two dots\n",
    "    #     (170, 50), (170, 70), (170, 90),    # third column\n",
    "    #     (50, 150), (50,170),                # second row first cell\n",
    "    #     (110,150), (110,170), (110,190),\n",
    "    #     (170,150),                          # ...\n",
    "    # ]\n",
    "    # # If you want to overlay on an actual high-res image of your scanned Braille page, set image_path\n",
    "    # image_path = None  # e.g., \"scan.jpg\"\n",
    "\n",
    "    res = segment_braille_cells(dots, image_path=img,\n",
    "                                visualize=True, deskew=True,\n",
    "                                tolerance_pct=0.03,\n",
    "                                dbscan_fallback=True,\n",
    "                                out_image_path=\"braille_cells_visualization.png\")\n",
    "\n",
    "    print(\"Detected cells (bboxes):\")\n",
    "    for i, bbox in enumerate(res['cells_bboxes'], 1):\n",
    "        print(f\"  Cell {i}: bbox={bbox}\")\n",
    "    print(\"dy (estimated vertical spacing):\", res['dy'])\n",
    "    print(\"angle (radians) used to deskew:\", res['angle_radians'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
